=== Automatically Committing Offsets

The way offsets are handled by a ann:configuration.kafka.annotation.KafkaListener[] bean is defined by the api:configuration.kafka.annotation.OffsetStrategy[] enum.

The following table summarizes the enum values and behaviour:

.Kafka Messaging Annotations
|===
|Value |Description

|api:configuration.kafka.annotation.OffsetStrategy#AUTO[]
|Automatically commit offsets. Sets `enable.auto.commit` to `true`

|api:configuration.kafka.annotation.OffsetStrategy#DISABLED[]
|Disables automatically committing offsets. Sets `enable.auto.commit` to `false`

|api:configuration.kafka.annotation.OffsetStrategy#SYNC[]
|Commits offsets manually at the end of each `poll()` loop if no exceptions occur. Sets `enable.auto.commit` to `false`

|api:configuration.kafka.annotation.OffsetStrategy#ASYNC[]
|Asynchronously commits offsets manually at the end of each `poll()` loop if no exceptions occur. Sets `enable.auto.commit` to `false`

|api:configuration.kafka.annotation.OffsetStrategy#SYNC_PER_RECORD[]
|Commits offsets manually after each `ConsumerRecord` is processed. Sets `enable.auto.commit` to `false`

|api:configuration.kafka.annotation.OffsetStrategy#ASYNC_PER_RECORD[]
|Commits offsets asynchronously after each `ConsumerRecord` is processed. Sets `enable.auto.commit` to `false`

|api:configuration.kafka.annotation.OffsetStrategy#SEND_TO_TRANSACTION[]
|Only available when the transactional producer is enabled for `@SendTo`. Sends offsets to transaction using method `sendOffsetsToTransaction` of `org.apache.kafka.clients.producer.Producer`.

|===

Depending on the your level of paranoia or durability requirements you can choose to tune how and when offsets are committed.

=== Manually Committing Offsets

If you set the `OffsetStrategy` to api:configuration.kafka.annotation.OffsetStrategy#DISABLED[] it becomes your responsibility to commit offsets.

There are a couple of ways that can be achieved.

The simplest way is to define an argument of type api:configuration.kafka.Acknowledgement[] and call the `ack()` method to commit offsets synchronously:

.Committing offsets with `ack()`
[source,java]
[source,java]
----
include::{testskafka}/consumer/offsets/ack/ProductListener.java[tags=method, indent=0]
----

<1> Committing offsets automatically is disabled
<2> The listener method specifies a parameter of type api:configuration.kafka.Acknowledgement[]
<3> The `ack()` method is called once the record has been processed

Alternatively, you an supply a `KafkaConsumer` method argument and then call `commitSync` (or `commitAsync`) yourself when you are ready to commit offsets:

.Committing offsets with the `KafkaConsumer` API
[source,java]
----
include::{testskafka}/consumer/offsets/manual/ProductListener.java[tags=imports, indent=0]

include::{testskafka}/consumer/offsets/manual/ProductListener.java[tags=method, indent=0]
----

<1> Committing offsets automatically is disabled
<2> The listener method specifies that it receives the offset data and a `KafkaConsumer`
<3> The `commitSync()` method is called once the record has been processed

=== Manually Assigning Offsets to a Consumer Bean

Sometimes you may wish to control exactly the position you wish to resume consuming messages from.

For example if you store offsets in a database you may wish to read the offsets from the database when the consumer starts and start reading from the position stored in the database.

To support this use case your consumer bean can implement the api:configuration.kafka.ConsumerSeekAware[] interface:

.Manually seeking offsets with the `ConsumerSeekAware` API

snippet::io.micronaut.kafka.docs.seek.ProductListener[]

<1> Implement the interface `ConsumerSeekAware`
<2> The `onPartitionsRevoked` can be used to save offsets
<3> The `onPartitionsAssigned` can use used to read offsets and seek to a specific position. In this trivial example we just seek to the offset 1 (skipping the first record).

TIP: api:configuration.kafka.ConsumerSeekAware[] provides a convenient api:configuration.kafka.seek.KafkaSeeker[] object that can be used to perform api:configuration.kafka.seek.KafkaSeekOperation[]s immediately on the underlying consumer.

Alternatively, when more fine-grained access to the Kafka consumer is required, your consumer bean can instead implement the link:{kafkaapi}/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html[ConsumerRebalanceListener] and api:configuration.kafka.ConsumerAware[] interfaces:

.Manually seeking offsets with the `KafkaConsumer` API

snippet::io.micronaut.kafka.docs.rebalance.ProductListener[]

<1> The `setKafkaConsumer` of the api:configuration.kafka.ConsumerAware[] allows access to the underlying consumer
<2> The `onPartitionsRevoked` can be used to save offsets
<3> The `onPartitionsAssigned` can use used to read offsets and seek to a specific position. In this trivial example we just seek to the offset 1 (skipping the first record).

=== Manual Offsets with Multiple Topics

It is possible for a single `@KafkaListener` bean to represent multiple consumers. If you have more than one method annotated with `@Topic` then `setKafkaConsumer` will be called multiple times for each backing consumer.


It is recommended in the case of manually seeking offsets that you use a single listener bean per consumer, the alternative is to store an internal `Set` of all consumers associated with a particular listener and manually search for the correct listener in the `onPartitionsAssigned` using the partition assignment data.

WARNING: Not doing so will lead to a `ConcurrentModificationException` error.

=== Manually Assigning Offsets from a Consumer Method

There may be some scenarios where you realize you need to `seek` to a different offset while consuming another one.

To support this use case, your consumer method can receive a api:configuration.kafka.seek.KafkaSeekOperations[] instance as a parameter:

snippet::io.micronaut.kafka.docs.seek.ops.ProductListener[]

<1> An instance of api:configuration.kafka.seek.KafkaSeekOperations[] will be injected to the method
<2> Any number of `seek` operations can be deferred. In this trivial example we just seek to the beginning of the partition.

The `seek` operations will be performed by Micronaut automatically, when the consumer method completes successfully, possibly after committing offsets via `OffsetStrategy.AUTO`.

TIP: These operations determine the next offset retrieved by `poll`. Take into account that, even if the `seek` operation performs successfully, your consumer method may keep receiving records that were cached by the previous call. You can configure `max.poll.records` to control the maximum number of records returned by a single call to `poll`.

==== Creating Kafka Seek Operations

The interface KafkaSeekOperation.api:configuration.kafka.seek.KafkaSeekOperation.Builder[] provides several methods to create `seek` operations:

* `seek`: Creates an absolute seek operation.
* `seekRelativeToBeginning`: Creates a seek operation relative to the beginning.
* `seekToBeginning`: Creates a seek to the beginning operation.
* `seekRelativeToEnd`: Creates a seek operation relative to the end.
* `seekToEnd`: Creates a seek to the end operation.
* `seekForward`: Creates a forward seek operation.
* `seekBackward`: Creates a backward seek operation.
* `seekToTimestamp`: Creates a seek to the timestamp operation.

TIP: Your `@KafkaListener` bean can inherit all these methods from this interface, so you can create `seek` operations directly from your consumer method.
