To add support for Kafka to an existing project, you should first add the Micronaut Kafka configuration to your build configuration. For example in Gradle:

dependency:micronaut-kafka[groupId="io.micronaut.kafka"]

== Configuring Kafka

The minimum requirement to configure Kafka is set the value of the `kafka.bootstrap.servers` property in `application.yml`:

.Configuring Kafka
[configuration]
----
kafka:
    bootstrap:
        servers: localhost:9092
----

The value can also be list of available servers:

.Configuring Kafka
[configuration]
----
kafka:
    bootstrap:
        servers:
            - foo:9092
            - bar:9092
----

TIP: You can also set the environment variable `KAFKA_BOOTSTRAP_SERVERS` to a comma separated list of values to externalize configuration.

If your broker needs to setup SSL, it can be configured this way:

.Configuring Kafka
[configuration]
----
kafka:
  bootstrap:
    servers: localhost:9092
  ssl:
    keystore:
      location: /path/to/client.keystore.p12
      password: secret
    truststore:
      location: /path/to/client.truststore.jks
      password: secret
      type: PKCS12
  security:
    protocol: ssl
----

== Creating a Kafka Producer with @KafkaClient

To create a Kafka `Producer` that sends messages you can simply define an interface that is annotated with ann:configuration.kafka.annotation.KafkaClient[].

For example the following is a trivial `@KafkaClient` interface:

.ProductClient.java

snippet::io.micronaut.kafka.docs.quickstart.ProductClient[tags="imports,clazz", indent=0]

<1> The ann:configuration.kafka.annotation.KafkaClient[] annotation is used to designate this interface as a client
<2> The ann:configuration.kafka.annotation.Topic[] annotation indicates which topics the `ProducerRecord` should be published to
<3> The method defines two parameters: The parameter that is the Kafka key and the value.
<4> It is also possible for the topic to be dynamic by making it a method argument

NOTE: You can omit the key, however this will result in a `null` key which means Kafka will not know how to partition the record.

At compile time Micronaut will produce an implementation of the above interface. You can retrieve an instance of `ProductClient` either by looking up the bean from the api:context.ApplicationContext[] or by injecting the bean with `@Inject`:

.Using ProductClient

snippet::io.micronaut.kafka.docs.quickstart.QuickstartTest[tags=quickstart, indent=0]

Note that since the `sendProduct` method returns `void` this means the method will send the `ProducerRecord` and block until the response is received. You can return a `Future` or rs:Publisher[] to support non-blocking message delivery.

== Creating a Kafka Consumer with @KafkaListener

To listen to Kafka messages you can use the ann:configuration.kafka.annotation.KafkaListener[] annotation to define a message listener.

The following example will listen for messages published by the `ProductClient` in the previous section:

.ProductListener.java

snippet::io.micronaut.kafka.docs.quickstart.ProductListener[tags="imports,clazz", indent=0]


<1> The ann:configuration.kafka.annotation.KafkaListener[] is used with `offsetReset` set to `EARLIEST` which makes the listener start listening to messages from the beginning of the partition.
<2> The ann:configuration.kafka.annotation.Topic[] annotation is again used to indicate which topic(s) to subscribe to.
<3> The `receive` method defines 2 arguments: The argument that will receive the key and the argument that will receive the value.

== Disabling Kafka
If for some reason, you need to disable the creation of kafka consumers, or producers, you can through configuration:

.Disabling Kafka
[configuration]
----
kafka:
  enabled: false
----
