<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
    <title>Micronaut Kafka</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" href="../css/main.css" type="text/css" media="screen, print" title="Style" charset="utf-8" />
    <link rel="stylesheet" href="../css/custom.css" type="text/css" media="screen, print" title="Style" charset="utf-8" />
    <link rel="stylesheet" href="../css/pdf.css" type="text/css" media="print" title="PDF" charset="utf-8" />
    <link rel="stylesheet" href="../css/highlight/agate.css">
    <script src="../js/highlight.pack.js"></script>
    <script src="../js/guide.js"></script>
    <script src="../js/multi-language-sample.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <link rel="stylesheet" href="../css/multi-language-sample.css"/>
    <script src="../js/docs.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.13/clipboard.min.js"></script>
    <script type="text/javascript">
        function addJsClass(el) {
            var classes = document.body.className.split(" ");
            classes.push("js");
            document.body.className = classes.join(" ");
        }
    </script>

</head>

<body class="body" id="docs" onload="addJsClass();" onhashchange="highlightMenu()">

<div id="table-of-content-nav-link" class="desktop">
    <a id="theme-switcher" title="Switch to dark theme" href="javascript:switchTheme(true)"><i class="fa fa-moon-o"></i></a>
    <a title="Collapse/Open Table of contents" title="Hide Table of Contents" href="javascript:hideTableOfContents();" class="button">[ + ]</a>
</div>

<div id="main">
    <div id="navigation" class="no-print">
        <div class="navTitle">
            <span id="logo"><a href="http://micronaut.io" title="Go to Micronaut Website"><img src="../img/micronaut-logo-white.svg" alt="Micronaut"/></a></span>
        </div>
        <div class="navLinks">
            <ul>
                    <li><div id="nav-summary" onmouseover="toggleNavSummary(false)" onmouseout="toggleNavSummary(true)" class="desktop">
                            <a href="../guide/index.html" class="button">Table of contents</a>
                            <div id="nav-summary-childs" style="display:none;">
                                
                                <div class="toc-item" style="margin-left:0"><a href="#introduction"><strong>1</strong><span>Introduction</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#releaseHistory"><strong>2</strong><span>Release History</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#kafkaCli"><strong>3</strong><span>Using the Micronaut CLI</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#kafkaQuickStart"><strong>4</strong><span>Kafka Quick Start</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#kafkaClient"><strong>5</strong><span>Kafka Producers Using @KafkaClient</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#kafkaListener"><strong>6</strong><span>Kafka Consumers Using @KafkaListener</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#kafkaApplications"><strong>7</strong><span>Running Kafka Applications</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#kafkaStreams"><strong>8</strong><span>Kafka Streams</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#kafkaGuides"><strong>9</strong><span>Guides</span></a></div>
                                
                                <div class="toc-item" style="margin-left:0"><a href="#repository"><strong>10</strong><span>Repository</span></a></div>
                                
                            </div>
                        </div>
                    </li>

                <li id="table-of-content-nav-link-mobile" class="mobile">
                    <a title="Scroll to Table of contents" href="javascript:scrollToTop();" class="button">Toc</a>
                </li>
                <li class="desktop">
                    <a title="Go to API documentation" href="../api/index.html" class="button">API Reference</a>
                </li>
                <li class="mobile">
                    <a title="Go to API documentation" href="../api/index.html" class="button">API</a>
                </li>
                <li class="desktop">
                    <a title="Go to Configuration Reference documentation" href="../guide/configurationreference.html" class="button">Configuration Reference</a>
                </li>
                <li class="mobile">
                    <a title="Go to Configuration Reference documentation" href="../guide/configurationreference.html" class="button">Conf</a>
                </li>
            </ul>

        </div>
    </div>
    
    <div id="table-of-content">
        <div class="toc-content">

        <h2>Table of Contents</h2>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-introduction"><a href="#introduction"><strong>1</strong><span>Introduction</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-releaseHistory"><a href="#releaseHistory"><strong>2</strong><span>Release History</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-kafkaCli"><a href="#kafkaCli"><strong>3</strong><span>Using the Micronaut CLI</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-kafkaQuickStart"><a href="#kafkaQuickStart"><strong>4</strong><span>Kafka Quick Start</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-kafkaClient"><a href="#kafkaClient"><strong>5</strong><span>Kafka Producers Using @KafkaClient</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaClientMethods"><a href="#kafkaClientMethods"><strong>5.1</strong><span>Defining @KafkaClient Methods</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaClientConfiguration"><a href="#kafkaClientConfiguration"><strong>5.2</strong><span>Configuring @KafkaClient beans</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaClientBatch"><a href="#kafkaClientBatch"><strong>5.3</strong><span>Sending Records in Batch</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaClientScope"><a href="#kafkaClientScope"><strong>5.4</strong><span>Injecting Kafka Producer Beans</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaClientTx"><a href="#kafkaClientTx"><strong>5.5</strong><span>Transactions</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaDockerized"><a href="#kafkaDockerized"><strong>5.6</strong><span>Running Kafka while testing and developing</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-kafkaListener"><a href="#kafkaListener"><strong>6</strong><span>Kafka Consumers Using @KafkaListener</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaListenerMethods"><a href="#kafkaListenerMethods"><strong>6.1</strong><span>Defining @KafkaListener Methods</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaListenerConfiguration"><a href="#kafkaListenerConfiguration"><strong>6.2</strong><span>Configuring @KafkaListener beans</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaOffsets"><a href="#kafkaOffsets"><strong>6.3</strong><span>Commiting Kafka Offsets</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaSeek"><a href="#kafkaSeek"><strong>6.4</strong><span>Assigning Kafka Offsets</span></a></div>
        
        <div class="toc-item" style="margin-left:20px" id="toc-item-manuallyAssigningOffsetsToAConsumerBean"><a href="#manuallyAssigningOffsetsToAConsumerBean"><strong>6.4.1</strong><span>Manually Assigning Offsets to a Consumer Bean</span></a></div>
        
        <div class="toc-item" style="margin-left:20px" id="toc-item-manualOffsetsWithMultipleTopics"><a href="#manualOffsetsWithMultipleTopics"><strong>6.4.2</strong><span>Manual Offsets with Multiple Topics</span></a></div>
        
        <div class="toc-item" style="margin-left:20px" id="toc-item-manuallyAssigningOffsetsFromAConsumerMethod"><a href="#manuallyAssigningOffsetsFromAConsumerMethod"><strong>6.4.3</strong><span>Manually Assigning Offsets from a Consumer Method</span></a></div>
        
        <div class="toc-item" style="margin-left:20px" id="toc-item-creatingKafkaSeekOperations"><a href="#creatingKafkaSeekOperations"><strong>6.4.4</strong><span>Creating Kafka Seek Operations</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaListenerBatch"><a href="#kafkaListenerBatch"><strong>6.5</strong><span>Kafka Batch Processing</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaSendTo"><a href="#kafkaSendTo"><strong>6.6</strong><span>Forwarding Messages with @SendTo</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaErrors"><a href="#kafkaErrors"><strong>6.7</strong><span>Handling Consumer Exceptions</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-kafkaApplications"><a href="#kafkaApplications"><strong>7</strong><span>Running Kafka Applications</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaHealth"><a href="#kafkaHealth"><strong>7.1</strong><span>Kafka Health Checks</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaMetrics"><a href="#kafkaMetrics"><strong>7.2</strong><span>Kafka Metrics</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaTracing"><a href="#kafkaTracing"><strong>7.3</strong><span>Kafka Distributed Tracing</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaNewTopics"><a href="#kafkaNewTopics"><strong>7.4</strong><span>Creating New Topics</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaDisabled"><a href="#kafkaDisabled"><strong>7.5</strong><span>Disabling Micronaut-Kafka</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-kafkaStreams"><a href="#kafkaStreams"><strong>8</strong><span>Kafka Streams</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaStreamInteractiveQuery"><a href="#kafkaStreamInteractiveQuery"><strong>8.1</strong><span>Interactive Query Service</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaStreamHealth"><a href="#kafkaStreamHealth"><strong>8.2</strong><span>Kafka Stream Health Checks</span></a></div>
        
        <div class="toc-item" style="margin-left:10px" id="toc-item-kafkaStreamExceptions"><a href="#kafkaStreamExceptions"><strong>8.3</strong><span>Handling Uncaught Exceptions</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-kafkaGuides"><a href="#kafkaGuides"><strong>9</strong><span>Guides</span></a></div>
        
        <div class="toc-item" style="margin-left:0px" id="toc-item-repository"><a href="#repository"><strong>10</strong><span>Repository</span></a></div>
        
        </div>
    </div>
    
    <div class="docs-content">
    <div class="project">
        <h1>Micronaut Kafka</h1>
        <p></p>
        <p>Integration between Micronaut and Kafka Messaging</p>
        <p><strong>Version:</strong> 5.6.1-SNAPSHOT </p>
    </div>
    
<h1 id="introduction"><a class="anchor" href="#introduction"></a>1 Introduction</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/introduction.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p><a href="https://kafka.apache.org">Apache Kafka</a> is a distributed stream processing platform that can be used for a range of messaging requirements in addition to stream processing and real-time data handling.</p>
</div>
<div class="paragraph">
<p>Micronaut features dedicated support for defining both Kafka <code>Producer</code> and <code>Consumer</code> instances. Micronaut applications built with Kafka can be deployed with or without the presence of an HTTP server.</p>
</div>
<div class="paragraph">
<p>With Micronaut&#8217;s efficient compile-time AOP and cloud native features, writing efficient Kafka consumer applications that use very little resources is a breeze.</p>
</div>

<h1 id="releaseHistory"><a class="anchor" href="#releaseHistory"></a>2 Release History</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/releaseHistory.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>For this project, you can find a list of releases (with release notes) here:</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/micronaut-projects/micronaut-kafka/releases">https://github.com/micronaut-projects/micronaut-kafka/releases</a></p>
</div>
<div class="sect2">
<h3 id="_upgrading_to_micronaut_kafka_5_0">Upgrading to Micronaut Kafka 5.0</h3>
<div class="paragraph">
<p>Micronaut Kafka 5.0 is a significant major version which includes a number of changes you will need to consider when upgrading.</p>
</div>
</div>
<div class="sect2">
<h3 id="_micronaut_4_kafka_3_java_17_baseline">Micronaut 4, Kafka 3 &amp; Java 17 baseline</h3>
<div class="paragraph">
<p>Micronaut Kafka 5.0 requires the following minimum set of dependencies:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Java 17 or above</p>
</li>
<li>
<p>Kafka 3</p>
</li>
<li>
<p>Micronaut 4 or above</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_kafkaclient_no_longer_recoverable_by_default"><code>@KafkaClient</code> no longer recoverable by default</h3>
<div class="paragraph">
<p>Previous versions of Micronaut Kafka used the meta-annotation <a href="https://docs.micronaut.io/latest/api/io/micronaut/retry/annotation/Recoverable.html">@Recoverable</a> on the <code>@KafkaClient</code> annotation allowing you to define <a href="https://docs.micronaut.io/latest/guide/#clientFallback">fallbacks</a> in the case of failure. Micronaut Kafka 5 no longer includes this meta annotation and if you use fallbacks you should explicitly declare a dependency on <code>io.micronaut:micronaut-retry</code> and declare the <code>@Recoverable</code> explicitly.</p>
</div>
</div>
<div class="sect2">
<h3 id="_open_tracing_no_longer_supported">Open Tracing No Longer Supported</h3>
<div class="paragraph">
<p>Micronaut Kafka 5 no longer supports Open Tracing (which is deprecated and no longer maintained) and if you need distributed tracing you should instead <a href="https://micronaut-projects.github.io/micronaut-tracing/latest/guide/#kafka">use Open Telemetry</a>.</p>
</div>
</div>

<h1 id="kafkaCli"><a class="anchor" href="#kafkaCli"></a>3 Using the Micronaut CLI</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaCli.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>To create a project with Kafka support using the Micronaut CLI, supply the <code>kafka</code> feature to the <code>features</code> flag.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ mn create-app my-kafka-app --features kafka</pre>
</div>
</div>
<div class="paragraph">
<p>This will create a project with the minimum necessary configuration for Kafka.</p>
</div>
<div class="sect1">
<h2 id="_kafka_messaging_application">Kafka Messaging Application</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Micronaut CLI includes the ability to create Kafka-based messaging applications designed to implement message-driven microservices.</p>
</div>
<div class="paragraph">
<p>To create a Message-Driven Microservice with Micronaut + Kafka use the <code>create-messaging-app</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ mn create-messaging-app my-kafka-app --features kafka</pre>
</div>
</div>
<div class="paragraph">
<p>As you&#8217;d expect, you can start the application with <code>./gradlew run</code> (for Gradle) or <code>./mvnw compile exec:exec</code> (Maven). The application will (with the default config) attempt to connect to Kafka at <code><a href="http://localhost:9092" class="bare">http://localhost:9092</a></code>, and will continue to run without starting up an HTTP server. All communication to/from the service will take place via Kafka producers and/or listeners.</p>
</div>
<div class="paragraph">
<p>Within the new project, you can now run the Kafka-specific code generation commands:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ mn create-kafka-producer MessageProducer
| Rendered template Producer.java to destination src/main/java/my/kafka/app/MessageProducer.java

$ mn create-kafka-listener MessageListener
| Rendered template Listener.java to destination src/main/java/my/kafka/app/MessageListener.java</pre>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
See the guide for <a href="https://guides.micronaut.io/latest/micronaut-kafka.html">Kafka and the Micronaut Framework - Event-driven Applications</a> to learn more.
</td>
</tr>
</table>
</div>
</div>
</div>

<h1 id="kafkaQuickStart"><a class="anchor" href="#kafkaQuickStart"></a>4 Kafka Quick Start</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaQuickStart.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>To add support for Kafka to an existing project, you should first add the Micronaut Kafka configuration to your build configuration. For example in Gradle:</p>
</div>
<div class="paragraph">
<p>        <div class="listingblock multi-language-sample">
<div class="title"></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="gradle">implementation(<span class="hljs-string">"io.micronaut.kafka:micronaut-kafka")</span></code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="maven">&lt;dependency&gt;
    &lt;groupId&gt;io.micronaut.kafka&lt;/groupId&gt;
    &lt;artifactId&gt;micronaut-kafka&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div></p>
</div>
<div class="sect1">
<h2 id="_configuring_kafka">Configuring Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The minimum requirement to configure Kafka is set the value of the <code>kafka.bootstrap.servers</code> property in <code>application.yml</code> or <code>bootstrap.yml</code> :</p>
</div>
<div class="openblock">
<div class="title">Configuring Kafka</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=localhost:9092</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    bootstrap:
        servers: localhost:9092</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.bootstrap]
    servers="localhost:9092"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  bootstrap {
    servers = "localhost:9092"
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    bootstrap {
      servers = "localhost:9092"
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "bootstrap": {
      "servers": "localhost:9092"
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The value can also be list of available servers:</p>
</div>
<div class="openblock">
<div class="title">Configuring Kafka</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers[0]=foo:9092
kafka.bootstrap.servers[1]=bar:9092</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    bootstrap:
        servers:
            - foo:9092
            - bar:9092</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.bootstrap]
    servers=[
      "foo:9092",
      "bar:9092"
    ]</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  bootstrap {
    servers = ["foo:9092", "bar:9092"]
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    bootstrap {
      servers = ["foo:9092", "bar:9092"]
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "bootstrap": {
      "servers": ["foo:9092", "bar:9092"]
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can also set the environment variable <code>KAFKA_BOOTSTRAP_SERVERS</code> to a comma separated list of values to externalize configuration.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You may also add any Apache Kafka configuration options directly under the kafka node. These configurations will apply to consumers, producers and streams:</p>
</div>
<div class="openblock">
<div class="title">Configuring Kafka</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=localhost:9092
kafka.reconnect.backoff.ms=30000
kafka.retry.backoff.ms=32000</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
  bootstrap:
    servers: localhost:9092
  reconnect.backoff.ms: 30000
  retry.backoff.ms: 32000</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  "reconnect.backoff.ms"=30000
  "retry.backoff.ms"=32000
  [kafka.bootstrap]
    servers="localhost:9092"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  bootstrap {
    servers = "localhost:9092"
  }
  reconnect.backoff.ms = 30000
  retry.backoff.ms = 32000
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    bootstrap {
      servers = "localhost:9092"
    }
    "reconnect.backoff.ms" = 30000
    "retry.backoff.ms" = 32000
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "bootstrap": {
      "servers": "localhost:9092"
    },
    "reconnect.backoff.ms": 30000,
    "retry.backoff.ms": 32000
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>If your broker needs to setup SSL, it can be configured this way:</p>
</div>
<div class="openblock">
<div class="title">Configuring Kafka</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=localhost:9093
kafka.ssl.keystore.location=/path/to/client.keystore.p12
kafka.ssl.keystore.password=secret
kafka.ssl.keystore.type=PKCS12
kafka.ssl.truststore.location=/path/to/client.truststore.p12
kafka.ssl.truststore.password=secret
kafka.ssl.truststore.type=PKCS12
kafka.security.protocol=ssl</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
  bootstrap:
    servers: localhost:9093
  ssl:
    keystore:
      location: /path/to/client.keystore.p12
      password: secret
      type: PKCS12
    truststore:
      location: /path/to/client.truststore.p12
      password: secret
      type: PKCS12
  security:
    protocol: ssl</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.bootstrap]
    servers="localhost:9093"
  [kafka.ssl]
    [kafka.ssl.keystore]
      location="/path/to/client.keystore.p12"
      password="secret"
      type="PKCS12"
    [kafka.ssl.truststore]
      location="/path/to/client.truststore.p12"
      password="secret"
      type="PKCS12"
  [kafka.security]
    protocol="ssl"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  bootstrap {
    servers = "localhost:9093"
  }
  ssl {
    keystore {
      location = "/path/to/client.keystore.p12"
      password = "secret"
      type = "PKCS12"
    }
    truststore {
      location = "/path/to/client.truststore.p12"
      password = "secret"
      type = "PKCS12"
    }
  }
  security {
    protocol = "ssl"
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    bootstrap {
      servers = "localhost:9093"
    }
    ssl {
      keystore {
        location = "/path/to/client.keystore.p12"
        password = "secret"
        type = "PKCS12"
      }
      truststore {
        location = "/path/to/client.truststore.p12"
        password = "secret"
        type = "PKCS12"
      }
    }
    security {
      protocol = "ssl"
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "bootstrap": {
      "servers": "localhost:9093"
    },
    "ssl": {
      "keystore": {
        "location": "/path/to/client.keystore.p12",
        "password": "secret",
        "type": "PKCS12"
      },
      "truststore": {
        "location": "/path/to/client.truststore.p12",
        "password": "secret",
        "type": "PKCS12"
      }
    },
    "security": {
      "protocol": "ssl"
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_creating_a_kafka_producer_with_kafkaclient">Creating a Kafka Producer with @KafkaClient</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To create a Kafka <code>Producer</code> that sends messages you can simply define an interface that is annotated with <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a>.</p>
</div>
<div class="paragraph">
<p>For example the following is a trivial <code>@KafkaClient</code> interface:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">ProductClient.java</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaClient;
import io.micronaut.configuration.kafka.annotation.KafkaKey;
import io.micronaut.configuration.kafka.annotation.Topic;
import io.micronaut.context.annotation.Requires;

@KafkaClient // <b class="conum">(1)</b>
public interface ProductClient {

    @Topic("my-products") // <b class="conum">(2)</b>
    void sendProduct(@KafkaKey String brand, String name); // <b class="conum">(3)</b>

    void sendProduct(@Topic String topic, @KafkaKey String brand, String name); // <b class="conum">(4)</b>
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">ProductClient.java</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.configuration.kafka.annotation.KafkaKey
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires

@KafkaClient // <b class="conum">(1)</b>
public interface ProductClient {

    @Topic('my-products') // <b class="conum">(2)</b>
    void sendProduct(@KafkaKey String brand, String name) // <b class="conum">(3)</b>

    void sendProduct(@Topic String topic, @KafkaKey String brand, String name) // <b class="conum">(4)</b>
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">ProductClient.java</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.configuration.kafka.annotation.KafkaKey
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires

@KafkaClient // <b class="conum">(1)</b>
interface ProductClient {
    @Topic("my-products")  // <b class="conum">(2)</b>
    fun sendProduct(@KafkaKey brand: String, name: String) // <b class="conum">(3)</b>

    fun sendProduct(@Topic topic: String, @KafkaKey brand: String, name: String) // <b class="conum">(4)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a> annotation is used to designate this interface as a client</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The <a href="../api/io/micronaut/configuration/kafka/annotation/Topic.html">@Topic</a> annotation indicates which topics the <code>ProducerRecord</code> should be published to</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The method defines two parameters: The parameter that is the Kafka key and the value.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>It is also possible for the topic to be dynamic by making it a method argument</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
You can omit the key, however this will result in a <code>null</code> key which means Kafka will not know how to partition the record.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>At compile time Micronaut will produce an implementation of the above interface. You can retrieve an instance of <code>ProductClient</code> either by looking up the bean from the <a href="../api/io/micronaut/context/ApplicationContext.html">ApplicationContext</a> or by injecting the bean with <code>@Inject</code>:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using ProductClient</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">ProductClient client = applicationContext.getBean(ProductClient.class);
client.sendProduct("Nike", "Blue Trainers");</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using ProductClient</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">val client = beanContext.getBean(ProductClient::class.java)
client.sendProduct("Nike", "Blue Trainers")</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that since the <code>sendProduct</code> method returns <code>void</code> this means the method will send the <code>ProducerRecord</code> and block until the response is received. You can specify an executor and return either a <code>CompletableFuture</code> or <a href="https://www.reactive-streams.org/reactive-streams-1.0.3-javadoc/org/reactivestreams/Publisher.html">Publisher</a> to support non-blocking message delivery.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_creating_a_kafka_consumer_with_kafkalistener">Creating a Kafka Consumer with @KafkaListener</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To listen to Kafka messages you can use the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> annotation to define a message listener.</p>
</div>
<div class="paragraph">
<p>The following example will listen for messages published by the <code>ProductClient</code> in the previous section:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">ProductListener.java</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaKey;
import io.micronaut.configuration.kafka.annotation.KafkaListener;
import io.micronaut.configuration.kafka.annotation.OffsetReset;
import io.micronaut.configuration.kafka.annotation.Topic;
import io.micronaut.context.annotation.Requires;
import org.slf4j.Logger;

import static org.slf4j.LoggerFactory.getLogger;

@KafkaListener(offsetReset = OffsetReset.EARLIEST) // <b class="conum">(1)</b>
public class ProductListener {
    private static final Logger LOG = getLogger(ProductListener.class);

    @Topic("my-products") // <b class="conum">(2)</b>
    public void receive(@KafkaKey String brand, String name) { // <b class="conum">(3)</b>
        LOG.info("Got Product - {} by {}", name, brand);
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">ProductListener.java</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.OffsetReset
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires

@Slf4j
@KafkaListener(offsetReset = OffsetReset.EARLIEST) // <b class="conum">(1)</b>
class ProductListener {

    @Topic('my-products') // <b class="conum">(2)</b>
    void receive(@KafkaKey String brand, String name) { // <b class="conum">(3)</b>
        log.info("Got Product - {} by {}", name, brand)
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">ProductListener.java</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaKey
import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.OffsetReset
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires
import org.slf4j.LoggerFactory

@KafkaListener(offsetReset = OffsetReset.EARLIEST) // <b class="conum">(1)</b>
class ProductListener {
    companion object {
        private val LOG = LoggerFactory.getLogger(ProductListener::class.java)
    }

    @Topic("my-products") // <b class="conum">(2)</b>
    fun receive(@KafkaKey brand: String, name: String) { // <b class="conum">(3)</b>
        LOG.info("Got Product - {} by {}", name, brand)
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> is used with <code>offsetReset</code> set to <code>EARLIEST</code> which makes the listener start listening to messages from the beginning of the partition.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The <a href="../api/io/micronaut/configuration/kafka/annotation/Topic.html">@Topic</a> annotation is again used to indicate which topic(s) to subscribe to.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>receive</code> method defines 2 arguments: The argument that will receive the key and the argument that will receive the value.</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_disabling_kafka">Disabling Kafka</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If for some reason, you need to disable the creation of kafka consumers, or producers, you can through configuration:</p>
</div>
<div class="openblock">
<div class="title">Disabling Kafka</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.enabled=false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
  enabled: false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  enabled=false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  enabled = false
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    enabled = false
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "enabled": false
  }
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>

<h1 id="kafkaClient"><a class="anchor" href="#kafkaClient"></a>5 Kafka Producers Using @KafkaClient</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaClient.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>




<h2 id="kafkaClientMethods"><a class="anchor" href="#kafkaClientMethods"></a>5.1 Defining @KafkaClient Methods</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaClient/kafkaClientMethods.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="sect2">
<h3 id="_specifying_the_key_and_the_value">Specifying the Key and the Value</h3>
<div class="paragraph">
<p>The Kafka key can be specified by providing a parameter annotated with <code>@KafkaKey</code>. If no such parameter is specified the record is sent with a <code>null</code> key.</p>
</div>
<div class="paragraph">
<p>The value to send is resolved by selecting the argument annotated with <a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/MessageBody.html">@MessageBody</a>, otherwise the first argument with no specific binding annotation is used. For example:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">    @Topic("my-products")
    void sendProduct(@KafkaKey String brand, String name);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">    @Topic('my-products')
    void sendProduct(@KafkaKey String brand, String name)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">    @Topic("my-products")
    fun sendProduct(@KafkaKey brand: String, name: String)</code></pre>
</div>
</div>
<div class="paragraph">
<p>The method above will use the parameter <code>brand</code> as the key and the parameter <code>name</code> as the value.</p>
</div>
</div>
<div class="sect2">
<h3 id="_including_message_headers">Including Message Headers</h3>
<div class="paragraph">
<p>There are a number of ways you can include message headers. One way is to annotate an argument with the <a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/MessageHeader.html">@MessageHeader</a> annotation and include a value when calling the method:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">    @Topic("my-products")
    void sendProduct(@KafkaKey String brand, String name, @MessageHeader("My-Header") String myHeader);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">    @Topic('my-products')
    void sendProduct(@KafkaKey String brand, String name, @MessageHeader('My-Header') String myHeader)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">    @Topic("my-products")
    fun sendProduct(@KafkaKey brand: String, name: String, @MessageHeader("My-Header") myHeader: String)</code></pre>
</div>
</div>
<div class="paragraph">
<p>The example above will include the value of the <code>myHeader</code> argument as a header called <code>My-Header</code>.</p>
</div>
<div class="paragraph">
<p>Another way to include headers is at the type level with the values driven from configuration:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Declaring @KafkaClient Headers</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaClient;
import io.micronaut.messaging.annotation.MessageHeader;

@KafkaClient(id="product-client")
@MessageHeader(name = "X-Token", value = "${my.application.token}")
public interface ProductClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Declaring @KafkaClient Headers</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.messaging.annotation.MessageHeader

@KafkaClient(id='product-client')
@MessageHeader(name = 'X-Token', value = '${my.application.token}')
interface ProductClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Declaring @KafkaClient Headers</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.messaging.annotation.MessageHeader

@KafkaClient(id = "product-client")
@MessageHeader(name = "X-Token", value = "\${my.application.token}")
interface ProductClient {
// define client API
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above example will send a header called <code>X-Token</code> with the value read from the setting <code>my.application.token</code> in <code>application.yml</code> (or the environnment variable <code>MY_APPLICATION_TOKEN</code>).</p>
</div>
<div class="paragraph">
<p>If the <code>my.application.token</code> is not set then an error will occur creating the client.</p>
</div>
<div class="paragraph">
<p>It is also possible to pass <code>Collection&lt;Header&gt;</code> or <code>Headers</code> object as method arguments as seen below.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Collection&lt;Header&gt; Argument</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">    @Topic("my-bicycles")
    void sendBicycle(@KafkaKey String brand, String model, Collection&lt;Header&gt; headers);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Collection&lt;Header&gt; Argument</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">    @Topic('my-bicycles')
    void sendBicycle(@KafkaKey String brand, String model, Collection&lt;Header&gt; headers)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Collection&lt;Header&gt; Argument</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">    @Topic("my-bicycles")
    fun sendBicycle(@KafkaKey brand: String, model: String, headers: Collection&lt;Header&gt;)</code></pre>
</div>
</div>
<div class="paragraph">
<p><a href="https://javadoc.io/doc/org.apache.kafka/kafka-clients/latest/org/apache/kafka/common/header/Header.html">Kafka Header Javadocs</a></p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Headers Argument</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">    @Topic("my-bicycles")
    void sendBicycle(@KafkaKey String brand, String model, Headers headers);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Headers Argument</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">    @Topic('my-bicycles')
    void sendBicycle(@KafkaKey String brand, String model, Headers headers)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Headers Argument</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">    @Topic("my-bicycles")
    fun sendBicycle(@KafkaKey brand: String, model: String, headers: Headers)</code></pre>
</div>
</div>
<div class="paragraph">
<p><a href="https://javadoc.io/doc/org.apache.kafka/kafka-clients/latest/org/apache/kafka/common/header/Headers.html">Kafka Headers Javadocs</a></p>
</div>
<div class="paragraph">
<p>In the above examples, all of the key/value pairs in <code>headers</code> will be added to the list of headers produced to the topic.  <code>Header</code> and <code>Headers</code> are
part of the <code>kafka-clients</code> library:</p>
</div>
</div>
<div class="sect2">
<h3 id="_reactive_and_non_blocking_method_definitions">Reactive and Non-Blocking Method Definitions</h3>
<div class="paragraph">
<p>The <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a> annotation supports the definition of reactive return types (such as <a href="http://reactivex.io/RxJava/2.x/javadoc/io/reactivex/Flowable.html">Flowable</a> or Reactor <code>Flux</code>) as well as Futures.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The KafkaProducer used internally to implement <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a> support is inherently blocking, even though some of its methods describe themselves as "asynchronous". Configuring an executor (as shown in the following examples) is required in order to guarantee that a returned reactive type or Future will not block the calling thread.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Add the library <a href="https://micronaut-projects.github.io/micronaut-reactor/latest/guide/">Micronaut Reactor</a> or <a href="https://micronaut-projects.github.io/micronaut-rxjava3/latest/guide/">Micronaut RxJava 3</a> to your application&#8217;s dependencies.</p>
</div>
<div class="paragraph">
<p>The following sections, which use Micronaut Reactor, cover advised configuration and possible method signatures and behaviour:</p>
</div>
<div class="sect3">
<h4 id="_configuring_an_executor">Configuring An Executor</h4>
<div class="paragraph">
<p>As the <code>send</code> method of <code>KafkaProducer</code> can block the calling thread, it is recommended that you specify an executor to be used when returning either reactive types or <code>CompletableFuture</code>. This will ensure that the <code>send</code> logic is executed on a separate thread from that of the caller, and avoid undesirable conditions such as blocking of the Micronaut server&#8217;s event loop.</p>
</div>
<div class="paragraph">
<p>The executor to be used may be specified via configuration properties as in the following example:</p>
</div>
<div class="openblock">
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.producers.default.executor=blocking
kafka.producers.my-named-producer.executor=io</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    producers:
        default:
            executor: blocking
        my-named-producer:
            executor: io</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.producers]
    [kafka.producers.default]
      executor="blocking"
    [kafka.producers.my-named-producer]
      executor="io"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  producers {
    'default' {
      executor = "blocking"
    }
    myNamedProducer {
      executor = "io"
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    producers {
      default {
        executor = "blocking"
      }
      my-named-producer {
        executor = "io"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "producers": {
      "default": {
        "executor": "blocking"
      },
      "my-named-producer": {
        "executor": "io"
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Alternatively, the executor may be specified via the <code>executor</code> property of the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a> annotation:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaClient(value = "product-client", executor = TaskExecutors.BLOCKING)
public interface BookClient {</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy"></code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin"></code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that an <code>executor</code> specified in the annotation will take precedent over that specified in the application configuration properties.</p>
</div>
</div>
<div class="sect3">
<h4 id="_mono_value_and_return_type">Mono Value and Return Type</h4>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">    @Topic("my-books")
    Mono&lt;Book&gt; sendBook(@KafkaKey String author, Mono&lt;Book&gt; book);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">    @Topic('my-books')
    Mono&lt;Book&gt; sendBook(@KafkaKey String author, Mono&lt;Book&gt; book);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">    @Topic("my-books")
    fun sendBook(@KafkaKey author: String, book: Mono&lt;Book&gt;): Mono&lt;Book&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The implementation will return a <code>Mono</code> that when subscribed to will subscribe to the passed <code>Mono</code> and send the emitted item as a <code>ProducerRecord</code> emitting the item again if successful or an error otherwise.</p>
</div>
</div>
<div class="sect3">
<h4 id="_flux_value_and_return_type">Flux Value and Return Type</h4>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">    @Topic("my-books")
    Flux&lt;RecordMetadata&gt; sendBooks(@KafkaKey String author, Flux&lt;Book&gt; book);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">    @Topic('my-books')
    Flux&lt;RecordMetadata&gt; sendBooks(@KafkaKey String author, Flux&lt;Book&gt; book);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">    @Topic("my-books")
    fun sendBooks(@KafkaKey author: String, book: Flux&lt;Book&gt;): Flux&lt;RecordMetadata&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The implementation will return a Reactor <code>Flux</code> that when subscribed to will subscribe to the passed <code>Flux</code> and for each emitted item will send a <code>ProducerRecord</code> emitting the resulting Kafka <code>RecordMetadata</code> if successful or an error otherwise.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_available_annotations">Available Annotations</h3>
<div class="paragraph">
<p>There are a number of annotations available that allow you to specify how a method argument is treated.</p>
</div>
<div class="paragraph">
<p>The following table summarizes the annotations and their purpose, with an example:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Kafka Messaging Annotations</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Annotation</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/MessageBody.html">@MessageBody</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows explicitly indicating the body of the message to sent</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@MessageBody Product product</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/MessageHeader.html">@MessageHeader</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows specifying a parameter that should be sent as a header</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@MessageHeader("X-My-Header") String myHeader</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/KafkaKey.html">@KafkaKey</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows specifying the parameter that is the Kafka key</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@KafkaKey String key</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/KafkaPartition.html">@KafkaPartition</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows specifying the parameter that is the partition number</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@KafkaPartition Integer partition</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/KafkaPartitionKey.html">@KafkaPartitionKey</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows specifying the parameter that is used to compute a partition number independently from the Message Key.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@KafkaPartition String partitionKey</code></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>For example, you can use the <a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/MessageHeader.html">@MessageHeader</a> annotation to bind a parameter value to a header in the <code>ProducerRecord</code>.</p>
</div>
</div>

<h2 id="kafkaClientConfiguration"><a class="anchor" href="#kafkaClientConfiguration"></a>5.2 Configuring @KafkaClient beans</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaClient/kafkaClientConfiguration.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="sect2">
<h3 id="_kafkaclient_and_producer_properties">@KafkaClient and Producer Properties</h3>
<div class="paragraph">
<p>There are a number of ways to pass configuration properties to the <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/producer/KafkaProducer.html">KafkaProducer</a>. You can set default producer properties using <code>kafka.producers.default</code> in <code>application.yml</code>:</p>
</div>
<div class="openblock">
<div class="title">Applying Default Configuration</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.producers.default.retries=5
kafka.producers.default.bootstrap.servers=localhost:9096</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    producers:
        default:
            retries: 5
            bootstrap:
              servers: localhost:9096</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.producers]
    [kafka.producers.default]
      retries=5
      [kafka.producers.default.bootstrap]
        servers="localhost:9096"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  producers {
    'default' {
      retries = 5
      bootstrap {
        servers = "localhost:9096"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    producers {
      default {
        retries = 5
        bootstrap {
          servers = "localhost:9096"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "producers": {
      "default": {
        "retries": 5,
        "bootstrap": {
          "servers": "localhost:9096"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Any property in the <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/producer/ProducerConfig.html">ProducerConfig</a> class can be set, <em>including</em> any overrides over the global Micronaut Kafka configs. The above example will set the default number of times to retry sending a record as well as override <code>kafka.bootstrap.servers</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_per_kafkaclient_producer_properties">Per @KafkaClient Producer Properties</h3>
<div class="paragraph">
<p>To configure different properties for each client, you should set a <code>@KafkaClient</code> id using the annotation:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a Client ID</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaClient("product-client")</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a Client ID</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaClient('product-client')</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a Client ID</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaClient("product-client")</code></pre>
</div>
</div>
<div class="paragraph">
<p>This serves 2 purposes. Firstly it sets the value of the <code>client.id</code> setting used to build the <code>Producer</code>. Secondly, it allows you to apply per producer configuration in <code>application.yml</code>:</p>
</div>
<div class="openblock">
<div class="title">Applying Default Configuration</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.producers.product-client.retries=5
kafka.producers.product-client.bootstrap.servers=localhost:9097
kafka.producers.product-client-2.bootstrap.servers=localhost:9098</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    producers:
        product-client:
            retries: 5
            bootstrap:
              servers: localhost:9097
        product-client-2:
            bootstrap:
              servers: localhost:9098</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.producers]
    [kafka.producers.product-client]
      retries=5
      [kafka.producers.product-client.bootstrap]
        servers="localhost:9097"
    [kafka.producers.product-client-2]
      [kafka.producers.product-client-2.bootstrap]
        servers="localhost:9098"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  producers {
    productClient {
      retries = 5
      bootstrap {
        servers = "localhost:9097"
      }
    }
    productClient2 {
      bootstrap {
        servers = "localhost:9098"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    producers {
      product-client {
        retries = 5
        bootstrap {
          servers = "localhost:9097"
        }
      }
      product-client-2 {
        bootstrap {
          servers = "localhost:9098"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "producers": {
      "product-client": {
        "retries": 5,
        "bootstrap": {
          "servers": "localhost:9097"
        }
      },
      "product-client-2": {
        "bootstrap": {
          "servers": "localhost:9098"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Finally, the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a> annotation itself provides a <code>properties</code> member that you can use to set producer specific properties:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Configuring Producer Properties with @KafkaClient</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaClient;
import io.micronaut.context.annotation.Property;
import io.micronaut.context.annotation.Requires;
import org.apache.kafka.clients.producer.ProducerConfig;

@KafkaClient(
    id = "product-client",
    acks = KafkaClient.Acknowledge.ALL,
    properties = @Property(name = ProducerConfig.RETRIES_CONFIG, value = "5")
)
public interface ProductClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Configuring Producer Properties with @KafkaClient</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.context.annotation.Property
import io.micronaut.context.annotation.Requires
import org.apache.kafka.clients.producer.ProducerConfig

@KafkaClient(
        id = "product-client",
        acks = KafkaClient.Acknowledge.ALL,
        properties = @Property(name = ProducerConfig.RETRIES_CONFIG, value = '5')
)
interface ProductClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Configuring Producer Properties with @KafkaClient</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.context.annotation.Property
import io.micronaut.context.annotation.Requires
import org.apache.kafka.clients.producer.ProducerConfig

@KafkaClient(
    id = "product-client",
    acks = KafkaClient.Acknowledge.ALL,
    properties = [Property(name = ProducerConfig.RETRIES_CONFIG, value = "5")]
)
interface ProductClient {
    // define client API
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_kafkaclient_and_serializers">@KafkaClient and Serializers</h3>
<div class="paragraph">
<p>When serializing keys and values Micronaut will by default attempt to automatically pick a <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/common/serialization/Serializer.html">Serializer</a> to use. This is done via the <a href="../api/io/micronaut/configuration/kafka/serde/CompositeSerdeRegistry.html">CompositeSerdeRegistry</a> bean.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can replace the default <a href="../api/io/micronaut/configuration/kafka/serde/SerdeRegistry.html">SerdeRegistry</a> bean with your own implementation by defining a bean that uses <code>@Replaces(CompositeSerdeRegistry.class)</code>. See the section on <a href="https://docs.micronaut.io/latest/guide/#replaces">Bean Replacement</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>All common <code>java.lang</code> types (<code>String</code>, <code>Integer</code>, primitives etc.) are supported and for POJOs by default a Jackson based JSON serializer is used.</p>
</div>
<div class="paragraph">
<p>You can, however, explicitly override the <code>Serializer</code> used by providing the appropriate configuration in <code>application.yml</code>:</p>
</div>
<div class="openblock">
<div class="title">Applying Default Configuration</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.producers.product-client.value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    producers:
        product-client:
            value:
                serializer: org.apache.kafka.common.serialization.ByteArraySerializer</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.producers]
    [kafka.producers.product-client]
      [kafka.producers.product-client.value]
        serializer="org.apache.kafka.common.serialization.ByteArraySerializer"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  producers {
    productClient {
      value {
        serializer = "org.apache.kafka.common.serialization.ByteArraySerializer"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    producers {
      product-client {
        value {
          serializer = "org.apache.kafka.common.serialization.ByteArraySerializer"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "producers": {
      "product-client": {
        "value": {
          "serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You may want to do this if for example you choose an alternative serialization format such as Avro or Protobuf.</p>
</div>
</div>

<h2 id="kafkaClientBatch"><a class="anchor" href="#kafkaClientBatch"></a>5.3 Sending Records in Batch</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaClient/kafkaClientBatch.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>By default if you define a method that takes a container type such as a <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/List.html">List</a> the list will be serialized using the specified <code>value.serializer</code> (the default will result in a JSON array).</p>
</div>
<div class="paragraph">
<p>For example the following two methods will both send serialized arrays:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending Arrays and Lists</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic("books")
void sendList(List&lt;Book&gt; books);

@Topic("books")
void sendBooks(Book...books);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending Arrays and Lists</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic('books')
void sendList(List&lt;Book&gt; books)

@Topic('books')
void sendBooks(Book...books)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending Arrays and Lists</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic("books")
fun sendList(books: List&lt;Book&gt;)

@Topic("books")
fun sendBooks(vararg books: Book)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Instead of a sending a serialized array you may wish to instead send batches of <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/producer/ProducerRecord.html">ProducerRecord</a> either synchronously or asynchronously.</p>
</div>
<div class="paragraph">
<p>To do this you can specify a value of <code>true</code> to the <code>batch</code> member of the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a> annotation:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaClient(batch = true)
public interface BookClient {

    @Topic("books")
    void sendList(List&lt;Book&gt; books);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaClient(batch = true)
interface BookClient {

    @Topic('books')
    void sendList(List&lt;Book&gt; books)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaClient(batch = true)
interface BookClient {

    @Topic("books")
    fun sendList(books: List&lt;Book&gt;)</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above case instead of sending a serialized array the client implementation will iterate over each item in the list and send a <code>ProducerRecord</code> for each. The previous example is blocking, however you can return a reactive type if desired:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches Reactively</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaClient(batch = true)
public interface BookClient {

    @Topic("books")
    Flux&lt;RecordMetadata&gt; send(List&lt;Book&gt; books);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches Reactively</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaClient(batch = true)
interface BookClient {

    @Topic('books')
    Flux&lt;RecordMetadata&gt; send(List&lt;Book&gt; books)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches Reactively</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaClient(batch = true)
interface BookClient {

    @Topic("books")
    fun send(books: List&lt;Book&gt;): Flux&lt;RecordMetadata&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also use an unbound reactive type such as <code>Flux</code> as the source of your batch data:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches from a Flux</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaClient(batch = true)
public interface BookClient {

    @Topic("books")
    Flux&lt;RecordMetadata&gt; send(Flux&lt;Book&gt; books);</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches from a Flux</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaClient(batch = true)
interface BookClient {

    @Topic('books')
    Flux&lt;RecordMetadata&gt; send(Flux&lt;Book&gt; books)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Sending <code>ProducerRecord</code> batches from a Flux</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaClient(batch = true)
interface BookClient {

    @Topic("books")
    fun send(books: Flux&lt;Book&gt;): Flux&lt;RecordMetadata&gt;</code></pre>
</div>
</div>

<h2 id="kafkaClientScope"><a class="anchor" href="#kafkaClientScope"></a>5.4 Injecting Kafka Producer Beans</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaClient/kafkaClientScope.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>If you need maximum flexibility and don&#8217;t want to use the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a> support you can use the <code>@KafkaClient</code> annotation as qualifier for dependency injection of <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/producer/KafkaProducer.html">KafkaProducer</a> instances.</p>
</div>
<div class="paragraph">
<p>Consider the following example:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a KafkaProducer directly</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaClient;
import io.micronaut.context.annotation.Requires;
import jakarta.inject.Singleton;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

import java.util.concurrent.Future;

@Singleton
public class BookSender {

    private final Producer&lt;String, Book&gt; kafkaProducer;

    public BookSender(@KafkaClient("book-producer") Producer&lt;String, Book&gt; kafkaProducer) { // <b class="conum">(1)</b>
        this.kafkaProducer = kafkaProducer;
    }

    public Future&lt;RecordMetadata&gt; send(String author, Book book) {
        return kafkaProducer.send(new ProducerRecord&lt;&gt;("books", author, book)); // <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a KafkaProducer directly</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.context.annotation.Requires
import jakarta.inject.Singleton
import org.apache.kafka.clients.producer.Producer
import org.apache.kafka.clients.producer.ProducerRecord
import org.apache.kafka.clients.producer.RecordMetadata

import java.util.concurrent.Future

@Singleton
class BookSender {

    private final Producer&lt;String, Book&gt; kafkaProducer

    BookSender(@KafkaClient('book-producer') Producer&lt;String, Book&gt; kafkaProducer) { // <b class="conum">(1)</b>
        this.kafkaProducer = kafkaProducer
    }

    Future&lt;RecordMetadata&gt; send(String author, Book book) {
        kafkaProducer.send(new ProducerRecord&lt;&gt;('books', author, book)) // <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a KafkaProducer directly</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.context.annotation.Requires
import jakarta.inject.Singleton
import org.apache.kafka.clients.producer.Producer
import org.apache.kafka.clients.producer.ProducerRecord
import org.apache.kafka.clients.producer.RecordMetadata
import java.util.concurrent.Future

@Requires(property = "spec.name", value = "BookSenderTest")
@Singleton
class BookSender(
    @param:KafkaClient("book-producer") private val kafkaProducer: Producer&lt;String, Book&gt;) { // <b class="conum">(1)</b>

    fun send(author: String, book: Book): Future&lt;RecordMetadata&gt; {
        return kafkaProducer.send(ProducerRecord("books", author, book)) // <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The <code>Producer</code> is dependency injected into the constructor. If not specified in configuration, the key and value serializer are inferred from the generic type arguments.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The <code>Producer</code> is used to send records</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Note that there is no need to call the <code>close()</code> method to shut down the <code>KafkaProducer</code>, it is fully managed by Micronaut and will be shutdown when the application shuts down.</p>
</div>
<div class="paragraph">
<p>The previous example can be tested in JUnit with the following test:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a KafkaProducer directly</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Test
void testBookSender() {

    try (ApplicationContext ctx = ApplicationContext.run( // <b class="conum">(1)</b>
        Map.of("kafka.enabled", "true", "spec.name", "BookSenderTest")
    )) {
        BookSender bookSender = ctx.getBean(BookSender.class); // <b class="conum">(2)</b>
        Book book = new Book("The Stand");
        Future&lt;RecordMetadata&gt; stephenKing = bookSender.send("Stephen King", book);
        assertDoesNotThrow(() -&gt; {
            RecordMetadata recordMetadata = stephenKing.get();
            assertEquals("books", recordMetadata.topic());
        });
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a KafkaProducer directly</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">void "test Book Sender"() {
    given:
    ApplicationContext ctx = ApplicationContext.run(  // <b class="conum">(1)</b>
        'kafka.enabled': true, 'spec.name': 'BookSenderTest'
    )
    BookSender bookSender = ctx.getBean(BookSender) // <b class="conum">(2)</b>
    Book book = new Book('The Stand')

    when:
    bookSender.send('Stephen King', book)
    Future&lt;RecordMetadata&gt; stephenKing = bookSender.send('Stephen King', book);
    def recordMetadata = stephenKing.get();

    then:
    noExceptionThrown()
    recordMetadata.topic() == 'books'

    cleanup:
    ctx.close()
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using a KafkaProducer directly</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Test
fun testBookSender() {
    ApplicationContext.run(mapOf( // <b class="conum">(1)</b>
        "kafka.enabled" to StringUtils.TRUE, "spec.name" to "BookSenderTest")).use { ctx -&gt;
        val bookSender = ctx.getBean(BookSender::class.java) // <b class="conum">(2)</b>
        val book = Book("The Stand")
        bookSender.send("Stephen King", book)
        val stephenKing = bookSender.send("Stephen King", book)
        Assertions.assertDoesNotThrow {
            val recordMetadata = stephenKing.get()
            Assertions.assertEquals("books", recordMetadata.topic())
        }
    }</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>A Kafka docker container is used</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The <code>BookSender</code> is retrieved from the <a href="../api/io/micronaut/context/ApplicationContext.html">ApplicationContext</a> and a <code>ProducerRecord</code> sent</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>By using the <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/producer/KafkaProducer.html">KafkaProducer</a> API directly you open up even more options if you require transactions (exactly-once delivery) or want control over when records are flushed etc.</p>
</div>

<h2 id="kafkaClientTx"><a class="anchor" href="#kafkaClientTx"></a>5.5 Transactions</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaClient/kafkaClientTx.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>Transaction processing can be enabled by defining <code>transactionalId</code> on <code>@KafkaClient</code>, which will initialize the producer for transactional usage and wrap any send operation with a transaction demarcation.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Transactional Client</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaClient(id = "my-client", transactionalId = "my-tx-id")
public interface TransactionalClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Transactional Client</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaClient(id = "my-client", transactionalId = "my-tx-id")
interface TransactionalClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Transactional Client</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaClient(id = "my-client", transactionalId = "my-tx-id")
interface TransactionalClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Alternative Kafka producer transactional code</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">producer.initTransactions();
try {
    producer.beginTransaction();
    producer.send(...);
    producer.commitTransaction();
} catch (Exception e) {
    producer.abortTransaction();
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>@KafkaClient</code> beans are by default singleton. When using multiple threads, you must either synchronize access to the individual instance or declare the bean as <code>@Prototype</code>. Additionally, you can use <a href="https://docs.micronaut.io/latest/guide/#_using_random_properties">random properties</a> to your advantage so that each instance of your producer gets a different transactional ID.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Random transactional ID</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Prototype
@KafkaClient(id = "my-client", transactionalId = "my-tx-id-${random.uuid}")
public interface RandomTransactionalIdClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Random transactional ID</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Prototype
@KafkaClient(id = "my-client", transactionalId = 'my-tx-id-${random.uuid}')
interface RandomTransactionalIdClient {
    // define client API
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Random transactional ID</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Prototype
@KafkaClient(id = "my-client", transactionalId = "my-tx-id-\${random.uuid}")
interface RandomTransactionalIdClient {
    // define client API
}</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>

<h2 id="kafkaDockerized"><a class="anchor" href="#kafkaDockerized"></a>5.6 Running Kafka while testing and developing</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaClient/kafkaDockerized.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p><a href="https://micronaut-projects.github.io/micronaut-test-resources/latest/guide/#modules-kafka">Micronaut Test Resources</a> simplifies running Kafka for local development and testing.</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Micronaut Test Resources Kafka support will automatically start a Kafka container and provide the value of the <code>kafka.bootstrap.servers</code> property.</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p><a href="https://micronaut.io/launch">Micronaut Launch</a> and CLI already apply Test Resources to your build when you <a href="https://micronaut.io/launch?features=kafka">select the <code>kafka</code> feature</a>.</p>
</div>
<div class="paragraph">
<p>Micronaut Test Resources uses <a href="https://testcontainers.com">Test Containers</a> under the hood. If you prefer to use Test Containers directly, you can create a <a href="https://www.testcontainers.org/test_framework_integration/manual_lifecycle_control/#singleton-containers">Singleton Container</a> and combine it with <a href="https://micronaut-projects.github.io/micronaut-test/latest/api/io/micronaut/test/support/TestPropertyProvider.html">Micronaut Test <code>TestPropertyProvider</code></a>:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package io.micronaut.kafka.docs;

import io.micronaut.test.support.TestPropertyProvider;
import org.testcontainers.containers.KafkaContainer;
import org.testcontainers.utility.DockerImageName;

import java.util.Collections;
import java.util.Map;

/**
 * @see &lt;a href="https://www.testcontainers.org/test_framework_integration/manual_lifecycle_control/#singleton-containers"&gt;Singleton containers&lt;/a&gt;
 */
public abstract class AbstractKafkaTest implements TestPropertyProvider {

    static protected final KafkaContainer MY_KAFKA = new KafkaContainer(
        DockerImageName.parse("confluentinc/cp-kafka:latest")
    );

    @Override
    public Map&lt;String, String&gt; getProperties() {
        if (!MY_KAFKA.isRunning()) {
            MY_KAFKA.start();
        }
        return Collections.singletonMap(
            "kafka.bootstrap.servers", MY_KAFKA.getBootstrapServers()
        );
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">package io.micronaut.kafka.docs

import io.micronaut.test.support.TestPropertyProvider
import org.testcontainers.containers.KafkaContainer
import org.testcontainers.utility.DockerImageName
import spock.lang.AutoCleanup
import spock.lang.Shared
import spock.lang.Specification

abstract class AbstractKafkaTest extends Specification implements TestPropertyProvider {

    @Shared
    @AutoCleanup
    KafkaContainer kafkaContainer = new KafkaContainer(DockerImageName.parse("confluentinc/cp-kafka:latest"))

    @Override
    Map&lt;String, String&gt; getProperties() {
        kafkaContainer.start()

        ["kafka.bootstrap.servers": kafkaContainer.getBootstrapServers()]
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">package io.micronaut.kafka.docs

import io.micronaut.test.support.TestPropertyProvider
import org.testcontainers.containers.KafkaContainer
import org.testcontainers.utility.DockerImageName

/**
 * @see &lt;a href="https://www.testcontainers.org/test_framework_integration/manual_lifecycle_control/#singleton-containers"&gt;Singleton containers&lt;/a&gt;
 */
abstract class AbstractKafkaTest : TestPropertyProvider {

    companion object {
        var MY_KAFKA: KafkaContainer = KafkaContainer(DockerImageName.parse("confluentinc/cp-kafka:latest"))
    }

    override fun getProperties(): MutableMap&lt;String, String&gt; {
        if(!MY_KAFKA.isRunning) {
            MY_KAFKA.start()
        }
        return mutableMapOf(
            "kafka.bootstrap.servers" to MY_KAFKA.bootstrapServers
        )
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>And then test:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package io.micronaut.kafka.docs;

import io.micronaut.configuration.kafka.annotation.KafkaClient;
import io.micronaut.configuration.kafka.annotation.KafkaListener;
import io.micronaut.configuration.kafka.annotation.OffsetReset;
import io.micronaut.configuration.kafka.annotation.Topic;
import io.micronaut.context.annotation.Property;
import io.micronaut.context.annotation.Requires;
import io.micronaut.test.extensions.junit5.annotation.MicronautTest;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.TestInstance;

import static java.util.concurrent.TimeUnit.SECONDS;
import static org.awaitility.Awaitility.await;

@Property(name = "spec.name", value = "MyTest")
@MicronautTest
@TestInstance(TestInstance.Lifecycle.PER_CLASS)
class MyTest extends AbstractKafkaTest {

    @Test
    void testKafkaRunning(MyProducer producer, MyConsumer consumer) {
        final String message = "hello";
        producer.produce(message);
        await().atMost(5, SECONDS).until(() -&gt; message.equals(consumer.consumed));
    }

    @Requires(property = "spec.name", value = "MyTest")
    @KafkaClient
    interface MyProducer {
        @Topic("my-topic")
        void produce(String message);
    }

    @Requires(property = "spec.name", value = "MyTest")
    @KafkaListener(offsetReset = OffsetReset.EARLIEST)
    static class MyConsumer {
        String consumed;
        @Topic("my-topic")
        public void consume(String message) {
            consumed = message;
        }
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">package io.micronaut.kafka.docs


import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.OffsetReset
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Property
import io.micronaut.context.annotation.Requires
import io.micronaut.test.extensions.spock.annotation.MicronautTest
import jakarta.inject.Inject
import spock.util.concurrent.PollingConditions

@MicronautTest
@Property(name = "spec.name", value = "MyTest")
class MyTest extends AbstractKafkaTest {

    @Inject
    MyProducer producer
    @Inject
    MyConsumer consumer

    PollingConditions conditions = new PollingConditions()

    void "test kafka running"() {
        given:
        String message = "hello"

        when:
        producer.produce(message)

        then:
        conditions.within(5) {
            consumer.consumed == message
        }
    }

    @Requires(property = "spec.name", value = "MyTest")
    @KafkaClient
    static interface MyProducer {
        @Topic("my-topic")
        void produce(String message)
    }

    @Requires(property = "spec.name", value = "MyTest")
    @KafkaListener(offsetReset = OffsetReset.EARLIEST)
    static class MyConsumer {
        String consumed

        @Topic("my-topic")
        void consume(String message) {
            consumed = message
        }
    }

}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">package io.micronaut.kafka.docs

import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.OffsetReset
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Property
import io.micronaut.context.annotation.Requires
import io.micronaut.test.extensions.junit5.annotation.MicronautTest
import org.awaitility.Awaitility.await
import org.junit.jupiter.api.Test
import org.junit.jupiter.api.TestInstance
import java.util.concurrent.TimeUnit

@Property(name = "spec.name", value = "MyTest")
@MicronautTest
@TestInstance(TestInstance.Lifecycle.PER_CLASS)
internal class MyTest : AbstractKafkaTest() {

    @Test
    fun testKafkaRunning(producer: MyProducer, consumer: MyConsumer) {
        val message = "hello"
        producer.produce(message)
        await().atMost(5, TimeUnit.SECONDS).until { consumer.consumed == message }
    }

    @Requires(property = "spec.name", value = "MyTest")
    @KafkaClient
    interface MyProducer {
        @Topic("my-topic")
        fun produce(message: String)
    }

    @Requires(property = "spec.name", value = "MyTest")
    @KafkaListener(offsetReset = OffsetReset.EARLIEST)
    class MyConsumer {
        var consumed: String? = null

        @Topic("my-topic")
        fun consume(message: String) {
            consumed = message
        }
    }
}</code></pre>
</div>
</div>

<h1 id="kafkaListener"><a class="anchor" href="#kafkaListener"></a>6 Kafka Consumers Using @KafkaListener</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>The quick start section presented a trivial example of what is possible with the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> annotation.</p>
</div>
<div class="paragraph">
<p>Using the <code>@KafkaListener</code> annotation Micronaut will build a <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/consumer/KafkaConsumer.html">KafkaConsumer</a> and start the <code>poll</code> loop by running the <code>KafkaConsumer</code> in a special <code>consumer</code> thread pool. You can configure the size of the thread pool based on the number of consumers in your application in <code>application.yml</code> as desired:</p>
</div>
<div class="openblock">
<div class="title">Configuring the <code>consumer</code> thread pool</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">micronaut.executors.consumer.type=fixed
micronaut.executors.consumer.nThreads=25</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">micronaut:
    executors:
        consumer:
            type: fixed
            nThreads: 25</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[micronaut]
  [micronaut.executors]
    [micronaut.executors.consumer]
      type="fixed"
      nThreads=25</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">micronaut {
  executors {
    consumer {
      type = "fixed"
      nThreads = 25
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  micronaut {
    executors {
      consumer {
        type = "fixed"
        nThreads = 25
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "micronaut": {
    "executors": {
      "consumer": {
        "type": "fixed",
        "nThreads": 25
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p><code>KafkaConsumer</code> instances are single threaded, hence for each <code>@KafkaListener</code> method you define a new thread is created to execute the <code>poll</code> loop.</p>
</div>
<div class="paragraph">
<p>You may wish to scale the number of consumers you have listening on a particular topic. There are several ways you may achieve this. You could for example run multiple instances of your application each containing a single consumer in each JVM.</p>
</div>
<div class="paragraph">
<p>Alternatively, you can also scale via threads. By setting the number of <code>threads</code> a particular consumer bean will create:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Scaling with Threads</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(groupId = "myGroup", threads = 10)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Scaling with Threads</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(groupId='myGroup', threads = 10)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Scaling with Threads</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(groupId = "myGroup", threads = 10)</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above example will create 10 <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/consumer/KafkaConsumer.html">KafkaConsumer</a> instances, each running in a unique thread and participating in the <code>myGroup</code> consumer group.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
@KafkaListener beans are by default singleton. When using multiple threads you must either synchronize access to local state or declare the bean as <code>@Prototype</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can also make your number of threads configurable by using <code>threadsValue</code>:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Dynamically Configuring Threads</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(groupId = "myGroup", threadsValue = "${my.thread.count}")</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Dynamically Configuring Threads</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(groupId = 'myGroup', threadsValue = '${my.thread.count}')</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Dynamically Configuring Threads</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(groupId = "myGroup", threadsValue = "\${my.thread.count}")</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>threads</code> will be overridden by <code>threadsValue</code> if they are both set.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>By default Micronaut will inspect the method signature of the method annotated with <code>@Topic</code> that will listen for <code>ConsumerRecord</code> instances and from the types infer an appropriate key and value <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/common/serialization/Deserializer.html">Deserializer</a>.</p>
</div>
<div class="openblock">
<div class="title">Applying Configuration</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.consumers.default.allow.auto.create.topics=true
kafka.consumers.product.bootstrap.servers=localhost:9098</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    consumers:
        default:
            allow.auto.create.topics: true
        product:
            bootstrap:
              servers: localhost:9098</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.consumers]
    [kafka.consumers.default]
      "allow.auto.create.topics"=true
    [kafka.consumers.product]
      [kafka.consumers.product.bootstrap]
        servers="localhost:9098"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  consumers {
    'default' {
      allow.auto.create.topics = true
    }
    product {
      bootstrap {
        servers = "localhost:9098"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    consumers {
      default {
        "allow.auto.create.topics" = true
      }
      product {
        bootstrap {
          servers = "localhost:9098"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "consumers": {
      "default": {
        "allow.auto.create.topics": true
      },
      "product": {
        "bootstrap": {
          "servers": "localhost:9098"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Any property in the <a href="https://kafka.apache.org/27/javadoc/\/org/apache/kafka/clients/consumer/ConsumerConfig.html">ConsumerConfig</a> class can be set for all <code>@KafkaListener</code> beans based on the . The above example will enable the consumer to create a topic if it doesn&#8217;t exist for the <code>default</code> (<code>@KafkaListener</code>) client and set a custom bootstrap server for the <code>product</code> client (<code>@KafkaListener(value = "product")</code>)</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
See the guide for <a href="https://guides.micronaut.io/latest/testing-micronaut-kafka-listener-using-testcontainers.html">Testing Kafka Listener using Testcontainers with the Micronaut Framework</a> to learn more.
</td>
</tr>
</table>
</div>

<h2 id="kafkaListenerMethods"><a class="anchor" href="#kafkaListenerMethods"></a>6.1 Defining @KafkaListener Methods</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaListenerMethods.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>The <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> annotation examples up until now have been relatively trivial, but Micronaut offers a lot of flexibility when it comes to the types of method signatures you can define.</p>
</div>
<div class="paragraph">
<p>The following sections detail examples of supported use cases.</p>
</div>
<div class="sect1">
<h2 id="_specifying_topics">Specifying Topics</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <a href="../api/io/micronaut/configuration/kafka/annotation/Topic.html">@Topic</a> annotation can be used at the method or the class level to specify which topics to be listened for.</p>
</div>
<div class="paragraph">
<p>Care needs to be taken when using <a href="../api/io/micronaut/configuration/kafka/annotation/Topic.html">@Topic</a> at the class level because every public method of the class annotated with <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> will become a Kafka consumer, which may be undesirable.</p>
</div>
<div class="paragraph">
<p>You can specify multiple topics to listen for:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Multiple Topics</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic({"fun-products", "awesome-products"})
public void receiveMultiTopics(@KafkaKey String brand, String name) {
    LOG.info("Got Product - {} by {}", name, brand);
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Multiple Topics</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic(['fun-products', 'awesome-products'])
void receiveMultiTopics(@KafkaKey String brand, String name) {
    log.info("Got Product - {} by {}", name, brand)
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Multiple Topics</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic("fun-products", "awesome-products")
fun receiveMultiTopics(@KafkaKey brand: String, name: String) {
    LOG.info("Got Product - {} by {}", name, brand)
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also specify one or many regular expressions to listen for:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using regular expressions to match Topics</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic(patterns="products-\\w+")
public void receivePatternTopics(@KafkaKey String brand, String name) {
    LOG.info("Got Product - {} by {}", name, brand);
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using regular expressions to match Topics</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic(patterns='products-\\w+')
void receivePatternTopics(@KafkaKey String brand, String name) {
    log.info("Got Product - {} by {}", name, brand)
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using regular expressions to match Topics</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic(patterns = ["products-\\w+"])
fun receivePatternTopics(@KafkaKey brand: String, name: String) {
    LOG.info("Got Product - {} by {}", name, brand)
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_available_annotations">Available Annotations</h2>
<div class="sectionbody">
<div class="paragraph">
<p>There are a number of annotations available that allow you to specify how a method argument is bound.</p>
</div>
<div class="paragraph">
<p>The following table summarizes the annotations and their purpose, with an example:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Kafka Messaging Annotations</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Annotation</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/MessageBody.html">@MessageBody</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows explicitly indicating the body of the message</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@MessageBody Product product</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/MessageHeader.html">@MessageHeader</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows binding a parameter to a message header</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@MessageHeader("X-My-Header") String myHeader</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/KafkaKey.html">@KafkaKey</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows binding a parameter to the message key</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@KafkaKey String messageKey</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/KafkaPartition.html">@KafkaPartition</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Allows binding a parameter to the partition the message was received from</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>@KafkaPartition Integer partition</code></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>For example, you can use the <a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/MessageHeader.html">@MessageHeader</a> annotation to bind a parameter value from a header contained within a <code>ConsumerRecord</code>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_topics_partitions_and_offsets">Topics, Partitions and Offsets</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If you want a reference to the topic, partition or offset it is a simple matter of defining a parameter for each.</p>
</div>
<div class="paragraph">
<p>The following table summarizes example parameters and how they related to the <code>ConsumerRecord</code> being processed:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. @KafkaListener Method Parameters</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>String topic</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name of the topic</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>long offset</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The offset of the <code>ConsumerRecord</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>int partition</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The partition of the <code>ConsumerRecord</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>long timestamp</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The timestamp of the <code>ConsumerRecord</code></p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>As an example, following listener method will receive all of the above mentioned parameters:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Parameters for offset, topic etc.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic("awesome-products")
public void receive(@KafkaKey String brand, // <b class="conum">(1)</b>
                    Product product, // <b class="conum">(2)</b>
                    long offset, // <b class="conum">(3)</b>
                    int partition, // <b class="conum">(4)</b>
                    String topic, // <b class="conum">(5)</b>
                    long timestamp) { // <b class="conum">(6)</b>
    LOG.info("Got Product - {} by {}",product.name(), brand);
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Parameters for offset, topic etc.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic('awesome-products')
void receive(@KafkaKey String brand,  // <b class="conum">(1)</b>
             Product product, // <b class="conum">(2)</b>
             long offset, // <b class="conum">(3)</b>
             int partition, // <b class="conum">(4)</b>
             String topic, // <b class="conum">(5)</b>
             long timestamp) { // <b class="conum">(6)</b>
    log.info("Got Product - {} by {}", product.name, brand)
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Parameters for offset, topic etc.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic("awesome-products")
fun receive(
    @KafkaKey brand: String,  // <b class="conum">(1)</b>
    product: Product,  // <b class="conum">(2)</b>
    offset: Long,  // <b class="conum">(3)</b>
    partition: Int,  // <b class="conum">(4)</b>
    topic: String?,  // <b class="conum">(5)</b>
    timestamp: Long // <b class="conum">(6)</b>
) {
    LOG.info("Got Product - {} by {}", product.name, brand)
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The Kafka key</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The message body</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The offset of the <code>ConsumerRecord</code></td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The partition of the <code>ConsumerRecord</code></td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>The topic. Note that the <code>@Topic</code> annotation supports multiple topics.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>The timestamp of the <code>ConsumerRecord</code></td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_receiving_a_consumerrecord">Receiving a ConsumerRecord</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If you prefer you can also receive the entire <code>ConsumerRecord</code> object being listened for. In this case you should specify appropriate generic types for the key and value of the <code>ConsumerRecord</code> so that Micronaut can pick the correct deserializer for each.</p>
</div>
<div class="paragraph">
<p>Consider the following example:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Parameters for offset, topic etc.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic("awesome-products")
public void receive(ConsumerRecord&lt;String, Product&gt; record) { // <b class="conum">(1)</b>
    Product product = record.value(); // <b class="conum">(2)</b>
    String brand = record.key(); // <b class="conum">(3)</b>
    LOG.info("Got Product - {} by {}",product.name(), brand);
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Parameters for offset, topic etc.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic("awesome-products")
public void receive(ConsumerRecord&lt;String, Product&gt; record) { // <b class="conum">(1)</b>
    Product product = record.value() // <b class="conum">(2)</b>
    String brand = record.key() // <b class="conum">(3)</b>
    log.info("Got Product - {} by {}", product.name, brand)
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying Parameters for offset, topic etc.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic("awesome-products")
fun receive(record: ConsumerRecord&lt;String, Product&gt;) { // <b class="conum">(1)</b>
    val name = record.value() // <b class="conum">(2)</b>
    val brand = record.key() // <b class="conum">(3)</b>
    LOG.info("Got Product - $name by $brand")
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The method signature accepts a <code>ConsumerRecord</code> that specifies a <code>String</code> for the key type and a POJO (<code>Product</code>) for the value type.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The <code>value()</code> method is used to retrieve the value</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>key()</code> method is used to retrieve the key</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_receiving_and_returning_reactive_types">Receiving and returning Reactive Types</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In addition to common Java types and POJOs you can also define listener methods that receive a Reactive type such as a <a href="http://reactivex.io/RxJava/2.x/javadoc/io/reactivex/Single.html">Single</a> or a Reactor <code>Mono</code>.</p>
</div>
<div class="paragraph">
<p>Add the library <a href="https://micronaut-projects.github.io/micronaut-reactor/latest/guide/">Micronaut Reactor</a> or <a href="https://micronaut-projects.github.io/micronaut-rxjava3/latest/guide/">Micronaut RxJava 3</a> to your application&#8217;s dependencies.</p>
</div>
<div class="paragraph">
<p>For example, using Reactor:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using Reactive Types</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic("reactive-products")
public Mono&lt;Product&gt; receive(@KafkaKey String brand,  // <b class="conum">(1)</b>
                             Mono&lt;Product&gt; productPublisher) { // <b class="conum">(2)</b>
    return productPublisher.doOnSuccess((product) -&gt;
        LOG.info("Got Product - {} by {}", product.name(), brand) // <b class="conum">(3)</b>
    );
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using Reactive Types</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic('reactive-products')
Mono&lt;Product&gt; receive(@KafkaKey String brand,  // <b class="conum">(1)</b>
                      Mono&lt;Product&gt; productPublisher) { // <b class="conum">(2)</b>
    return productPublisher.doOnSuccess(product -&gt;
        log.info("Got Product - {} by {}", product.name, brand) // <b class="conum">(3)</b>
    )
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Using Reactive Types</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic("reactive-products")
fun receive(@KafkaKey brand: String,  // <b class="conum">(1)</b>
    product: Mono&lt;Product&gt;): Mono&lt;Product&gt; { // <b class="conum">(2)</b>
    return product.doOnSuccess { (name): Product -&gt;
        LOG.info("Got Product - {} by {}", name, brand) // <b class="conum">(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The <code>@KafkaKey</code> annotation is used to indicate the key</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>A <code>Mono</code> is used to receive the message body</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>doOnSuccess</code> method is used to process the result</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Note that in this case the method returns a <code>Mono</code> that indicates to Micronaut the <code>poll</code> loop should continue, and if <code>enable.auto.commit</code> is set to <code>true</code> (the default) the offsets will be committed, potentially before the <code>doOnSuccess</code> is called.</p>
</div>
<div class="paragraph">
<p>The idea here is that you are able to write consumers that don&#8217;t block, however care must be taken in the case where an error occurs in the <code>doOnSuccess</code> method otherwise the message could be lost. You could for example re-deliver the message in case of an error.</p>
</div>
<div class="paragraph">
<p>Alternatively, you can use the <a href="https://micronaut-projects.github.io/micronaut-core/latest/api/io/micronaut/core/annotation/Blocking.html">@Blocking</a> annotation to tell Micronaut to subscribe to the returned reactive type in a blocking manner which will result in blocking the <code>poll</code> loop, preventing offsets from being committed automatically:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Blocking with Reactive Consumers</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Blocking
@Topic("reactive-products")
public Mono&lt;Product&gt; receiveBlocking(@KafkaKey String brand, Mono&lt;Product&gt; productPublisher) {
    return productPublisher.doOnSuccess((product) -&gt;
        LOG.info("Got Product - {} by {}", product.name(), brand)
    );
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Blocking with Reactive Consumers</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Blocking
@Topic('reactive-products')
Mono&lt;Product&gt; receiveBlocking(@KafkaKey String brand, Mono&lt;Product&gt; productPublisher) {
    return productPublisher.doOnSuccess(product -&gt;
            log.info("Got Product - {} by {}", product.name, brand)
    )
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Blocking with Reactive Consumers</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Blocking
@Topic("reactive-products")
fun receiveBlocking(@KafkaKey brand: String, product: Mono&lt;Product&gt;): Mono&lt;Product&gt; {
    return product.doOnSuccess { (name): Product -&gt;
        LOG.info("Got Product - {} by {}", name, brand)
    }
}</code></pre>
</div>
</div>
</div>
</div>

<h2 id="kafkaListenerConfiguration"><a class="anchor" href="#kafkaListenerConfiguration"></a>6.2 Configuring @KafkaListener beans</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaListenerConfiguration.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="sect2">
<h3 id="_kafkalistener_and_consumer_groups">@KafkaListener and Consumer Groups</h3>
<div class="paragraph">
<p>Kafka consumers created with <code>@KafkaListener</code> will by default run within a consumer group that is the value of <code>micronaut.application.name</code> unless you explicitly specify a value to the <code>@KafkaListener</code> annotation. For example:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying a Consumer Group</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener("myGroup")</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying a Consumer Group</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener('myGroup')</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying a Consumer Group</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener("myGroup")</code></pre>
</div>
</div>
<div class="paragraph">
<p>or</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying a Consumer Group alternative</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(groupId = "myGroup")</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying a Consumer Group alternative</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(groupId = 'myGroup')</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying a Consumer Group alternative</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(groupId = "myGroup")</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above examples will run the consumer within a consumer group called <code>myGroup</code>.
In this case, each record will be consumed by one consumer instance of the consumer group.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can make the consumer group configurable using a placeholder: <code>@KafkaListener("${my.consumer.group:myGroup}")</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To allow the records to be consumed by all the consumer instances (each instance will be part of a unique consumer group), <code>uniqueGroupId</code> can be set to <code>true</code>:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Unique group IDs</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(groupId = "myGroup", uniqueGroupId = true)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Unique group IDs</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(groupId = 'myGroup', uniqueGroupId = true)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Unique group IDs</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(groupId = "myGroup", uniqueGroupId = true)</code></pre>
</div>
</div>
<div class="paragraph">
<p>For more information, see for example <a href="https://kafka.apache.org/intro#intro_consumers" class="bare">https://kafka.apache.org/intro#intro_consumers</a></p>
</div>
</div>
<div class="sect2">
<h3 id="_kafkalistener_and_consumer_properties">@KafkaListener and Consumer Properties</h3>
<div class="paragraph">
<p>There are a number of ways to pass configuration properties to the <code>KafkaConsumer</code>. You can set default consumer properties using <code>kafka.consumers.default</code> in <code>application.yml</code>:</p>
</div>
<div class="openblock">
<div class="title">Applying Default Configuration</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.consumers.default.session.timeout.ms=30000</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    consumers:
        default:
            session:
                timeout:
                    ms: 30000</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.consumers]
    [kafka.consumers.default]
      [kafka.consumers.default.session]
        [kafka.consumers.default.session.timeout]
          ms=30000</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  consumers {
    'default' {
      session {
        timeout {
          ms = 30000
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    consumers {
      default {
        session {
          timeout {
            ms = 30000
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "consumers": {
      "default": {
        "session": {
          "timeout": {
            "ms": 30000
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The above example will set the default <code>session.timeout.ms</code> that Kafka uses to decide whether a consumer is alive or not and applies it to all created <code>KafkaConsumer</code> instances.</p>
</div>
<div class="paragraph">
<p>You can also provide configuration specific to a consumer group. For example consider the following configuration:</p>
</div>
<div class="openblock">
<div class="title">Applying Consumer Group Specific config</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.consumers.myGroup.session.timeout.ms=30000</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    consumers:
        myGroup:
            session:
                timeout:
                    ms: 30000</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.consumers]
    [kafka.consumers.myGroup]
      [kafka.consumers.myGroup.session]
        [kafka.consumers.myGroup.session.timeout]
          ms=30000</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  consumers {
    myGroup {
      session {
        timeout {
          ms = 30000
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    consumers {
      myGroup {
        session {
          timeout {
            ms = 30000
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "consumers": {
      "myGroup": {
        "session": {
          "timeout": {
            "ms": 30000
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The above configuration will pass properties to only the <code>@KafkaListener</code> beans that apply to the consumer group <code>myGroup</code>.</p>
</div>
<div class="paragraph">
<p>Finally, the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> annotation itself provides a <code>properties</code> member that you can use to set consumer specific properties:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Configuring Consumer Properties with @KafkaListener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaKey;
import io.micronaut.configuration.kafka.annotation.KafkaListener;
import io.micronaut.configuration.kafka.annotation.Topic;
import io.micronaut.context.annotation.Property;
import io.micronaut.context.annotation.Requires;
import io.micronaut.kafka.docs.Product;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.slf4j.Logger;

import static org.slf4j.LoggerFactory.getLogger;

@KafkaListener(
    groupId = "products",
    pollTimeout = "500ms",
    properties = @Property(name = ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, value = "10000")
)
public class ProductListener {</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Configuring Consumer Properties with @KafkaListener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaKey
import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Property
import io.micronaut.context.annotation.Requires
import io.micronaut.kafka.docs.Product
import org.apache.kafka.clients.consumer.ConsumerConfig
import org.apache.kafka.clients.consumer.ConsumerRecord

@KafkaListener(
        groupId = 'products',
        pollTimeout = '500ms',
        properties = @Property(name = ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, value = '10000')
)
class ProductListener {</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Configuring Consumer Properties with @KafkaListener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaKey
import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Property
import io.micronaut.context.annotation.Requires
import io.micronaut.kafka.docs.Product
import io.micronaut.kafka.docs.consumer.topics.ProductListener
import org.apache.kafka.clients.consumer.ConsumerConfig
import org.apache.kafka.clients.consumer.ConsumerRecord
import org.slf4j.LoggerFactory


@KafkaListener(
    groupId = "products",
    pollTimeout = "500ms",
    properties = [Property(name = ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, value = "10000")]
)
class ProductListener {</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_kafkalistener_and_deserializers">@KafkaListener and Deserializers</h3>
<div class="paragraph">
<p>As mentioned previously when defining <code>@KafkaListener</code> methods, Micronaut will attempt to pick an appropriate deserializer for the method signature. This is done via the <a href="../api/io/micronaut/configuration/kafka/serde/CompositeSerdeRegistry.html">CompositeSerdeRegistry</a> bean.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can replace the default <a href="../api/io/micronaut/configuration/kafka/serde/SerdeRegistry.html">SerdeRegistry</a> bean with your own implementation by defining a bean that uses <code>@Replaces(CompositeSerdeRegistry.class)</code>. See the section on <a href="https://docs.micronaut.io/latest/guide/#replaces">Bean Replacement</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>All common <code>java.lang</code> types (<code>String</code>, <code>Integer</code>, primitives etc.) are supported and for POJOs by default a Jackson based JSON deserializer is used.</p>
</div>
<div class="paragraph">
<p>You can, however, explicitly override the <code>Deserializer</code> used by providing the appropriate configuration in <code>application.yml</code>:</p>
</div>
<div class="openblock">
<div class="title">Applying Default Configuration</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.consumers.myGroup.value.deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    consumers:
        myGroup:
            value:
                deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.consumers]
    [kafka.consumers.myGroup]
      [kafka.consumers.myGroup.value]
        deserializer="org.apache.kafka.common.serialization.ByteArrayDeserializer"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  consumers {
    myGroup {
      value {
        deserializer = "org.apache.kafka.common.serialization.ByteArrayDeserializer"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    consumers {
      myGroup {
        value {
          deserializer = "org.apache.kafka.common.serialization.ByteArrayDeserializer"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "consumers": {
      "myGroup": {
        "value": {
          "deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You may want to do this if for example you choose an alternative deserialization format such as Avro or Protobuf.</p>
</div>
</div>
<div class="sect2">
<h3 id="_transactional_properties">Transactional properties</h3>
<div class="paragraph">
<p>There are a few options that can be enabled for only in the transactional processing:</p>
</div>
<div class="sect3">
<h4 id="_isolation">Isolation</h4>
<div class="paragraph">
<p>Use <code>isolation</code> member to define if you want to receive messages that haven&#8217;t been committed yet.</p>
</div>
</div>
<div class="sect3">
<h4 id="_custom_offset_strategy">Custom offset strategy</h4>
<div class="paragraph">
<p>There is a special offset strategy <code>OffsetStrategy.SEND_TO_TRANSACTION</code> that can only be used with an associated producer, only applicable when <code>SendTo</code> is used.</p>
</div>
</div>
</div>

<h2 id="kafkaOffsets"><a class="anchor" href="#kafkaOffsets"></a>6.3 Commiting Kafka Offsets</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaOffsets.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="sect2">
<h3 id="_automatically_committing_offsets">Automatically Committing Offsets</h3>
<div class="paragraph">
<p>The way offsets are handled by a <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> bean is defined by the <a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html">OffsetStrategy</a> enum.</p>
</div>
<div class="paragraph">
<p>The following table summarizes the enum values and behaviour:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Kafka Messaging Annotations</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#AUTO">AUTO</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Automatically commit offsets. Sets <code>enable.auto.commit</code> to <code>true</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#DISABLED">DISABLED</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Disables automatically committing offsets. Sets <code>enable.auto.commit</code> to <code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#SYNC">SYNC</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Commits offsets manually at the end of each <code>poll()</code> loop if no exceptions occur. Sets <code>enable.auto.commit</code> to <code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#ASYNC">ASYNC</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Asynchronously commits offsets manually at the end of each <code>poll()</code> loop if no exceptions occur. Sets <code>enable.auto.commit</code> to <code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#SYNC_PER_RECORD">SYNC_PER_RECORD</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Commits offsets manually after each <code>ConsumerRecord</code> is processed. Sets <code>enable.auto.commit</code> to <code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#ASYNC_PER_RECORD">ASYNC_PER_RECORD</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Commits offsets asynchronously after each <code>ConsumerRecord</code> is processed. Sets <code>enable.auto.commit</code> to <code>false</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#SEND_TO_TRANSACTION">SEND_TO_TRANSACTION</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Only available when the transactional producer is enabled for <code>@SendTo</code>. Sends offsets to transaction using method <code>sendOffsetsToTransaction</code> of <code>org.apache.kafka.clients.producer.Producer</code>.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Depending on the your level of paranoia or durability requirements you can choose to tune how and when offsets are committed.</p>
</div>
</div>
<div class="sect2">
<h3 id="_manually_committing_offsets">Manually Committing Offsets</h3>
<div class="paragraph">
<p>If you set the <code>OffsetStrategy</code> to <a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#DISABLED">DISABLED</a> it becomes your responsibility to commit offsets.</p>
</div>
<div class="paragraph">
<p>There are a couple of ways that can be achieved.</p>
</div>
<div class="paragraph">
<p>The simplest way is to define an argument of type <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.Acknowledge.html">Acknowledge</a> and call the <code>ack()</code> method to commit offsets synchronously:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing offsets with <code>ack()</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED) // <b class="conum">(1)</b>
public class ProductListener {

    @Topic("awesome-products")
    public void receive(Product product, Acknowledgement acknowledgement) { // <b class="conum">(2)</b>
        // process product record
        acknowledgement.ack(); // <b class="conum">(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing offsets with <code>ack()</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED) // <b class="conum">(1)</b>
class ProductListener {

    @Topic('awesome-products')
    void receive(Product product, Acknowledgement acknowledgement) { // <b class="conum">(2)</b>
        // process product record
        acknowledgement.ack() // <b class="conum">(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing offsets with <code>ack()</code></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED) // <b class="conum">(1)</b>
class ProductListener {

    @Topic("awesome-products")
    fun receive(product: Product, acknowledgement: Acknowledgement) { // <b class="conum">(2)</b>
        // process product record
        acknowledgement.ack() // <b class="conum">(3)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Committing offsets automatically is disabled</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The listener method specifies a parameter of type <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.Acknowledge.html">Acknowledge</a></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>ack()</code> method is called once the record has been processed</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Alternatively, you an supply a <code>KafkaConsumer</code> method argument and then call <code>commitSync</code> (or <code>commitAsync</code>) yourself when you are ready to commit offsets:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing offsets with the <code>KafkaConsumer</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaListener;
import io.micronaut.configuration.kafka.annotation.Topic;
import io.micronaut.context.annotation.Requires;
import io.micronaut.kafka.docs.Product;
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;

import java.util.Collections;

import static io.micronaut.configuration.kafka.annotation.OffsetReset.EARLIEST;
import static io.micronaut.configuration.kafka.annotation.OffsetStrategy.DISABLED;

@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED) // <b class="conum">(1)</b>
public class ProductListener {

    @Topic("awesome-products")
    public void receive(Product product, long offset, int partition, String topic, Consumer kafkaConsumer) { // <b class="conum">(2)</b>
        // process product record

        // commit offsets
        kafkaConsumer.commitSync(Collections.singletonMap( // <b class="conum">(3)</b>
                new TopicPartition(topic, partition),
                new OffsetAndMetadata(offset + 1, "my metadata")
        ));
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing offsets with the <code>KafkaConsumer</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires
import io.micronaut.kafka.docs.Product
import org.apache.kafka.clients.consumer.Consumer
import org.apache.kafka.clients.consumer.OffsetAndMetadata
import org.apache.kafka.common.TopicPartition

import static io.micronaut.configuration.kafka.annotation.OffsetReset.EARLIEST
import static io.micronaut.configuration.kafka.annotation.OffsetStrategy.DISABLED

@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED) // <b class="conum">(1)</b>
class ProductListener {

    @Topic('awesome-products')
    void receive(Product product, long offset, int partition, String topic, Consumer kafkaConsumer) { // <b class="conum">(2)</b>
        // process product record

        // commit offsets
        kafkaConsumer.commitSync(Collections.singletonMap( // <b class="conum">(3)</b>
                new TopicPartition(topic, partition),
                new OffsetAndMetadata(offset + 1, 'my metadata')
        ))
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing offsets with the <code>KafkaConsumer</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires
import io.micronaut.kafka.docs.Product
import org.apache.kafka.clients.consumer.Consumer
import org.apache.kafka.clients.consumer.OffsetAndMetadata
import org.apache.kafka.common.TopicPartition
import java.util.*

import io.micronaut.configuration.kafka.annotation.OffsetReset.EARLIEST
import io.micronaut.configuration.kafka.annotation.OffsetStrategy.DISABLED

@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED) // <b class="conum">(1)</b>
class ProductListener {

    @Topic("awesome-products")
    fun receive(product: Product, offset: Long, partition: Int, topic: String, kafkaConsumer: Consumer&lt;*, *&gt;) { // <b class="conum">(2)</b>
        // process product record

        // commit offsets
        kafkaConsumer.commitSync(Collections.singletonMap( // <b class="conum">(3)</b>
                TopicPartition(topic, partition),
                OffsetAndMetadata(offset + 1, "my metadata")
            )
        )
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Committing offsets automatically is disabled</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The listener method specifies that it receives the offset data and a <code>KafkaConsumer</code></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>commitSync()</code> method is called once the record has been processed</td>
</tr>
</table>
</div>
</div>

<h2 id="kafkaSeek"><a class="anchor" href="#kafkaSeek"></a>6.4 Assigning Kafka Offsets</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaSeek.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>




<h2 id="manuallyAssigningOffsetsToAConsumerBean"><a class="anchor" href="#manuallyAssigningOffsetsToAConsumerBean"></a>6.4.1 Manually Assigning Offsets to a Consumer Bean</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaSeek/manuallyAssigningOffsetsToAConsumerBean.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>Sometimes you may wish to control exactly the position you wish to resume consuming messages from.</p>
</div>
<div class="paragraph">
<p>For example if you store offsets in a database you may wish to read the offsets from the database when the consumer starts and start reading from the position stored in the database.</p>
</div>
<div class="paragraph">
<p>To support this use case your consumer bean can implement the <a href="../api/io/micronaut/configuration/kafka/ConsumerSeekAware.html">ConsumerSeekAware</a> interface:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Manually seeking offsets with the <code>ConsumerSeekAware</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package io.micronaut.kafka.docs.seek.aware;

import io.micronaut.configuration.kafka.ConsumerSeekAware;
import io.micronaut.configuration.kafka.annotation.*;
import io.micronaut.configuration.kafka.seek.*;
import io.micronaut.context.annotation.Requires;
import io.micronaut.kafka.docs.Product;
import org.apache.kafka.common.TopicPartition;
import java.util.*;

@KafkaListener
@Requires(property = "spec.name", value = "ConsumerSeekAwareTest")
public class ProductListener implements ConsumerSeekAware { // <b class="conum">(1)</b>

    List&lt;Product&gt; processed = new ArrayList&lt;&gt;();

    public ProductListener(ProductListenerConfiguration config) {
        // ...
    }

    @Topic("wonderful-products")
    void receive(Product product) {
        processed.add(product);
    }

    @Override
    public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) { // <b class="conum">(2)</b>
        // save offsets here
    }

    @Override
    public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions, KafkaSeeker seeker) { // <b class="conum">(3)</b>
        // seek to offset here
        partitions.stream().map(tp -&gt; KafkaSeekOperation.seek(tp, 1)).forEach(seeker::perform);
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Manually seeking offsets with the <code>ConsumerSeekAware</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">package io.micronaut.kafka.docs.seek.aware

import io.micronaut.configuration.kafka.ConsumerSeekAware
import io.micronaut.configuration.kafka.annotation.*
import io.micronaut.configuration.kafka.seek.*
import io.micronaut.context.annotation.Requires
import io.micronaut.kafka.docs.Product
import org.apache.kafka.common.TopicPartition

@KafkaListener
@Requires(property = "spec.name", value = "ConsumerSeekAwareSpec")
class ProductListener implements ConsumerSeekAware { // <b class="conum">(1)</b>

    List&lt;Product&gt; processed = []

    ProductListener(ProductListenerConfiguration config) {
        // ...
    }

    @Topic("wonderful-products")
    void receive(Product product) {
        processed &lt;&lt; product
    }

    @Override
    void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) { // <b class="conum">(2)</b>
        // save offsets here
    }

    @Override
    void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions, KafkaSeeker seeker) { // <b class="conum">(3)</b>
        // seek to offset here
        partitions.collect { KafkaSeekOperation.seek(it, 1) }.each(seeker.&amp;perform)
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Manually seeking offsets with the <code>ConsumerSeekAware</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">package io.micronaut.kafka.docs.seek.aware

import io.micronaut.configuration.kafka.ConsumerSeekAware
import io.micronaut.configuration.kafka.annotation.*
import io.micronaut.configuration.kafka.seek.*
import io.micronaut.context.annotation.Requires
import io.micronaut.kafka.docs.Product
import org.apache.kafka.common.TopicPartition

@KafkaListener
@Requires(property = "spec.name", value = "ConsumerSeekAwareTest")
class ProductListener constructor(config: ProductListenerConfiguration) : ConsumerSeekAware { // <b class="conum">(1)</b>

    var processed: MutableList&lt;Product&gt; = mutableListOf()

    @Topic("wonderful-products")
    fun receive(product: Product) {
        processed.add(product)
    }

    override fun onPartitionsRevoked(partitions: Collection&lt;TopicPartition&gt;) { // <b class="conum">(2)</b>
        // save offsets here
    }

    override fun onPartitionsAssigned(partitions: Collection&lt;TopicPartition&gt;, seeker: KafkaSeeker) { // <b class="conum">(3)</b>
        // seek to offset here
        partitions.stream().map { tp -&gt; KafkaSeekOperation.seek(tp, 1) }.forEach(seeker::perform)
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Implement the interface <code>ConsumerSeekAware</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The <code>onPartitionsRevoked</code> can be used to save offsets</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>onPartitionsAssigned</code> can use used to read offsets and seek to a specific position. In this trivial example we just seek to the offset 1 (skipping the first record).</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<a href="../api/io/micronaut/configuration/kafka/ConsumerSeekAware.html">ConsumerSeekAware</a> provides a convenient <a href="../api/io/micronaut/configuration/kafka/seek/KafkaSeeker.html">KafkaSeeker</a> object that can be used to perform <a href="../api/io/micronaut/configuration/kafka/seek/KafkaSeekOperation.html">KafkaSeekOperation</a>s immediately on the underlying consumer.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Alternatively, when more fine-grained access to the Kafka consumer is required, your consumer bean can instead implement the <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html">ConsumerRebalanceListener</a> and <a href="../api/io/micronaut/configuration/kafka/ConsumerAware.html">ConsumerAware</a> interfaces:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Manually seeking offsets with the <code>KafkaConsumer</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package io.micronaut.kafka.docs.seek.rebalance;

import io.micronaut.configuration.kafka.ConsumerAware;
import io.micronaut.configuration.kafka.annotation.*;
import io.micronaut.context.annotation.Requires;
import io.micronaut.kafka.docs.Product;
import io.micronaut.core.annotation.NonNull;
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.TopicPartition;
import java.util.*;

@KafkaListener(offsetReset = OffsetReset.EARLIEST)
@Requires(property = "spec.name", value = "ConsumerRebalanceListenerTest")
public class ProductListener implements ConsumerRebalanceListener, ConsumerAware {

    List&lt;Product&gt; processed = new ArrayList&lt;&gt;();
    private Consumer consumer;

    public ProductListener(ProductListenerConfiguration config) {
        // ...
    }

    @Override
    public void setKafkaConsumer(@NonNull Consumer consumer) { // <b class="conum">(1)</b>
        this.consumer = consumer;
    }

    @Topic("fantastic-products")
    void receive(Product product) {
        processed.add(product);
    }

    @Override
    public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) { // <b class="conum">(2)</b>
        // save offsets here
    }

    @Override
    public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) { // <b class="conum">(3)</b>
        // seek to offset here
        for (TopicPartition partition : partitions) {
            consumer.seek(partition, 1);
        }
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Manually seeking offsets with the <code>KafkaConsumer</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">package io.micronaut.kafka.docs.seek.rebalance

import io.micronaut.configuration.kafka.ConsumerAware
import io.micronaut.configuration.kafka.annotation.*
import io.micronaut.context.annotation.Requires
import io.micronaut.core.annotation.NonNull
import io.micronaut.kafka.docs.Product
import org.apache.kafka.clients.consumer.*
import org.apache.kafka.common.TopicPartition

@KafkaListener(offsetReset = OffsetReset.EARLIEST)
@Requires(property = "spec.name", value = "ConsumerRebalanceListenerSpec")
class ProductListener implements ConsumerRebalanceListener, ConsumerAware {

    List&lt;Product&gt; processed = []
    private Consumer consumer

    ProductListener(ProductListenerConfiguration config) {
        // ...
    }

    @Override
    void setKafkaConsumer(@NonNull Consumer consumer) { // <b class="conum">(1)</b>
        this.consumer = consumer
    }

    @Topic("fantastic-products")
    void receive(Product product) {
        processed &lt;&lt; product
    }

    @Override
    void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) { // <b class="conum">(2)</b>
        // save offsets here
    }

    @Override
    void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) { // <b class="conum">(3)</b>
        // seek to offset here
        for (TopicPartition partition : partitions) {
            consumer.seek(partition, 1)
        }
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Manually seeking offsets with the <code>KafkaConsumer</code> API</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">package io.micronaut.kafka.docs.seek.rebalance

import io.micronaut.configuration.kafka.ConsumerAware
import io.micronaut.configuration.kafka.annotation.*
import io.micronaut.context.annotation.Requires
import io.micronaut.kafka.docs.Product
import org.apache.kafka.clients.consumer.*
import org.apache.kafka.common.TopicPartition

@KafkaListener(offsetReset = OffsetReset.EARLIEST)
@Requires(property = "spec.name", value = "ConsumerRebalanceListenerTest")
class ProductListener constructor(config: ProductListenerConfiguration) : ConsumerRebalanceListener, ConsumerAware&lt;Any?, Any?&gt; {

    var processed: MutableList&lt;Product&gt; = mutableListOf()
    private var consumer: Consumer&lt;*, *&gt;? = null

    override fun setKafkaConsumer(consumer: Consumer&lt;Any?, Any?&gt;?) { // <b class="conum">(1)</b>
        this.consumer = consumer
    }

    @Topic("fantastic-products")
    fun receive(product: Product) {
        processed.add(product)
    }

    override fun onPartitionsRevoked(partitions: Collection&lt;TopicPartition&gt;) { // <b class="conum">(2)</b>
        // save offsets here
    }

    override fun onPartitionsAssigned(partitions: Collection&lt;TopicPartition&gt;) { // <b class="conum">(3)</b>
        // seek to offset here
        for (partition in partitions) {
            consumer!!.seek(partition, 1)
        }
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The <code>setKafkaConsumer</code> of the <a href="../api/io/micronaut/configuration/kafka/ConsumerAware.html">ConsumerAware</a> allows access to the underlying consumer</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The <code>onPartitionsRevoked</code> can be used to save offsets</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>onPartitionsAssigned</code> can use used to read offsets and seek to a specific position. In this trivial example we just seek to the offset 1 (skipping the first record).</td>
</tr>
</table>
</div>

<h2 id="manualOffsetsWithMultipleTopics"><a class="anchor" href="#manualOffsetsWithMultipleTopics"></a>6.4.2 Manual Offsets with Multiple Topics</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaSeek/manualOffsetsWithMultipleTopics.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>It is possible for a single <code>@KafkaListener</code> bean to represent multiple consumers. If you have more than one method annotated with <code>@Topic</code> then <code>setKafkaConsumer</code> will be called multiple times for each backing consumer.</p>
</div>
<div class="paragraph">
<p>It is recommended in the case of manually seeking offsets that you use a single listener bean per consumer, the alternative is to store an internal <code>Set</code> of all consumers associated with a particular listener and manually search for the correct listener in the <code>onPartitionsAssigned</code> using the partition assignment data.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Not doing so will lead to a <code>ConcurrentModificationException</code> error.
</td>
</tr>
</table>
</div>

<h2 id="manuallyAssigningOffsetsFromAConsumerMethod"><a class="anchor" href="#manuallyAssigningOffsetsFromAConsumerMethod"></a>6.4.3 Manually Assigning Offsets from a Consumer Method</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaSeek/manuallyAssigningOffsetsFromAConsumerMethod.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>There may be some scenarios where you realize you need to <code>seek</code> to a different offset while consuming another one.</p>
</div>
<div class="paragraph">
<p>To support this use case, your consumer method can receive a <a href="../api/io/micronaut/configuration/kafka/seek/KafkaSeekOperations.html">KafkaSeekOperations</a> instance as a parameter:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">package io.micronaut.kafka.docs.seek.ops;

import io.micronaut.configuration.kafka.annotation.*;
import io.micronaut.configuration.kafka.seek.*;
import io.micronaut.context.annotation.*;
import io.micronaut.kafka.docs.Product;
import org.apache.kafka.common.TopicPartition;
import java.util.*;

@KafkaListener(offsetReset = OffsetReset.EARLIEST, properties = @Property(name = "max.poll.records", value = "1"))
@Requires(property = "spec.name", value = "KafkaSeekOperationsTest")
public class ProductListener {

    List&lt;Product&gt; processed = new ArrayList&lt;&gt;();

    public ProductListener(ProductListenerConfiguration config) {
        // ...
    }

    @Topic("amazing-products")
    void receive(Product product, KafkaSeekOperations ops) { // <b class="conum">(1)</b>
        processed.add(product);
        ops.defer(KafkaSeekOperation.seekToEnd(new TopicPartition("amazing-products", 0))); // <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">package io.micronaut.kafka.docs.seek.ops

import io.micronaut.configuration.kafka.annotation.*
import io.micronaut.configuration.kafka.seek.*
import io.micronaut.context.annotation.*
import io.micronaut.kafka.docs.Product
import org.apache.kafka.common.TopicPartition

@KafkaListener(offsetReset = OffsetReset.EARLIEST, properties = @Property(name = "max.poll.records", value = "1"))
@Requires(property = "spec.name", value = "KafkaSeekOperationsSpec")
class ProductListener {

    List&lt;Product&gt; processed = []

    ProductListener(ProductListenerConfiguration config) {
        // ...
    }

    @Topic("amazing-products")
    void receive(Product product, KafkaSeekOperations ops) { // <b class="conum">(1)</b>
        processed &lt;&lt; product
        ops.defer(KafkaSeekOperation.seekToEnd(new TopicPartition("amazing-products", 0))); // <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">package io.micronaut.kafka.docs.seek.ops

import io.micronaut.configuration.kafka.annotation.*
import io.micronaut.configuration.kafka.seek.*
import io.micronaut.context.annotation.*
import io.micronaut.kafka.docs.Product
import org.apache.kafka.common.TopicPartition

@KafkaListener(offsetReset = OffsetReset.EARLIEST, properties = [Property(name = "max.poll.records", value = "1")])
@Requires(property = "spec.name", value = "KafkaSeekOperationsTest")
class ProductListener constructor(config: ProductListenerConfiguration) {

    var processed: MutableList&lt;Product&gt; = mutableListOf()

    @Topic("amazing-products")
    fun receive(product: Product, ops: KafkaSeekOperations) { // <b class="conum">(1)</b>
        processed.add(product)
        ops.defer(KafkaSeekOperation.seekToBeginning(TopicPartition("amazing-products", 0))) // <b class="conum">(2)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>An instance of <a href="../api/io/micronaut/configuration/kafka/seek/KafkaSeekOperations.html">KafkaSeekOperations</a> will be injected to the method</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Any number of <code>seek</code> operations can be deferred. In this trivial example we just seek to the end of the partition.</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The <code>seek</code> operations will be performed by Micronaut automatically, when the consumer method completes successfully, possibly after committing offsets via <code>OffsetStrategy.AUTO</code>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
These operations determine the next offset retrieved by <code>poll</code>. Take into account that, even if the <code>seek</code> operation performs successfully, your consumer method may keep receiving records that were cached by the previous call. You can configure <code>max.poll.records</code> to control the maximum number of records returned by a single call to <code>poll</code>.
</td>
</tr>
</table>
</div>

<h2 id="creatingKafkaSeekOperations"><a class="anchor" href="#creatingKafkaSeekOperations"></a>6.4.4 Creating Kafka Seek Operations</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaSeek/creatingKafkaSeekOperations.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>The interface KafkaSeekOperation.<a href="../api/io/micronaut/configuration/kafka/seek/KafkaSeekOperation.html">KafkaSeekOperation</a> provides several static methods to create <code>seek</code> operations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>seek</code>: Creates an absolute seek operation.</p>
</li>
<li>
<p><code>seekRelativeToBeginning</code>: Creates a seek operation relative to the beginning.</p>
</li>
<li>
<p><code>seekToBeginning</code>: Creates a seek to the beginning operation.</p>
</li>
<li>
<p><code>seekRelativeToEnd</code>: Creates a seek operation relative to the end.</p>
</li>
<li>
<p><code>seekToEnd</code>: Creates a seek to the end operation.</p>
</li>
<li>
<p><code>seekForward</code>: Creates a forward seek operation.</p>
</li>
<li>
<p><code>seekBackward</code>: Creates a backward seek operation.</p>
</li>
<li>
<p><code>seekToTimestamp</code>: Creates a seek to the timestamp operation.</p>
</li>
</ul>
</div>

<h2 id="kafkaListenerBatch"><a class="anchor" href="#kafkaListenerBatch"></a>6.5 Kafka Batch Processing</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaListenerBatch.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>By default <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> listener methods will receive each <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/consumer/ConsumerRecord.html">ConsumerRecord</a> one by one.</p>
</div>
<div class="paragraph">
<p>There may be cases where you prefer to receive all of the <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/consumer/ConsumerRecord.html">ConsumerRecord</a> data from the <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/consumer/ConsumerRecords.html">ConsumerRecords</a> holder object in one go.</p>
</div>
<div class="paragraph">
<p>To achieve this you can set the <code>batch</code> member of the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> to <code>true</code> and specify a container type (typically <code>List</code>) to receive all of the data:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Receiving a Batch of Records</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaListener;
import io.micronaut.configuration.kafka.annotation.Topic;
import io.micronaut.context.annotation.Requires;
import org.slf4j.Logger;
import reactor.core.publisher.Flux;

import java.util.List;

import static org.slf4j.LoggerFactory.getLogger;

@KafkaListener(batch = true) // <b class="conum">(1)</b>
public class BookListener {

@Topic("all-the-books")
public void receiveList(List&lt;Book&gt; books) { // <b class="conum">(2)</b>
    for (Book book : books) {
        LOG.info("Got Book = {}", book.title()); // <b class="conum">(3)</b>
    }
}

}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Receiving a Batch of Records</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires
import reactor.core.publisher.Flux

@KafkaListener(batch = true) // <b class="conum">(1)</b>
@Slf4j
class BookListener {

@Topic("all-the-books")
void receiveList(List&lt;Book&gt; books) { // <b class="conum">(2)</b>
    for (Book book : books) {
        log.info("Got Book = {}", book.title) // <b class="conum">(3)</b>
    }
}

}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Receiving a Batch of Records</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires
import org.slf4j.LoggerFactory.getLogger
import reactor.core.publisher.Flux
import java.util.*

@KafkaListener(batch = true) // <b class="conum">(1)</b>
class BookListener {

@Topic("all-the-books")
fun receiveList(books: List&lt;Book&gt;) { // <b class="conum">(2)</b>
    for (book in books) {
        LOG.info("Got Book = {}", book.title) // <b class="conum">(3)</b>
    }
}

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> annotation&#8217;s <code>batch</code> member is set to <code>true</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The method defines that it receives a list of <code>Book</code> instances</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The method processes the entire batch</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Note in the previous case offsets will automatically be committed for the whole batch by default when the method returns without error.</p>
</div>
<div class="sect1">
<h2 id="_manually_committing_offsets_with_batch">Manually Committing Offsets with Batch</h2>
<div class="sectionbody">
<div class="paragraph">
<p>As with one by one message processing, if you set the <code>OffsetStrategy</code> to <a href="../api/io/micronaut/configuration/kafka/annotation/OffsetStrategy.html#DISABLED">DISABLED</a> it becomes your responsibility to commit offsets.</p>
</div>
<div class="paragraph">
<p>If you want to commit the entire batch of offsets at once during the course of processing, then the simplest approach is to add an argument of type <a href="{apimicronaut}messaging/Acknowledgement.html">Acknowledgement</a> and call the <code>ack()</code> method to commit the batch of offsets synchronously:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing a Batch of Offsets Manually with ack()</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
public void receive(List&lt;Book&gt; books, Acknowledgement acknowledgement) { // <b class="conum">(2)</b>

    //process the books

    acknowledgement.ack(); // <b class="conum">(3)</b>
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing a Batch of Offsets Manually with ack()</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
void receive(List&lt;Book&gt; books, Acknowledgement acknowledgement) { // <b class="conum">(2)</b>

    //process the books

    acknowledgement.ack() // <b class="conum">(3)</b>
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing a Batch of Offsets Manually with ack()</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(offsetReset = OffsetReset.EARLIEST, offsetStrategy = OffsetStrategy.DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
fun receive(books: List&lt;Book?&gt;?, acknowledgement: Acknowledgement) { // <b class="conum">(2)</b>

    //process the books

    acknowledgement.ack() // <b class="conum">(3)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Committing offsets automatically is disabled</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The listener method specifies a parameter of type <a href="{apimicronaut}messaging/Acknowledgement.html">Acknowledgement</a></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The <code>ack()</code> method is called once the records have been processed</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can also take more control of committing offsets when doing batch processing by specifying a method that receives the offsets in addition to the batch:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing Offsets Manually with Batch</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
public void receive(List&lt;ConsumerRecord&lt;String, Book&gt;&gt; records, Consumer kafkaConsumer) { // <b class="conum">(2)</b>

    for (int i = 0; i &lt; records.size(); i++) {
        ConsumerRecord&lt;String, Book&gt; record = records.get(i); // <b class="conum">(3)</b>

        // process the book
        Book book = record.value();

        // commit offsets
        String topic = record.topic();
        int partition = record.partition();
        long offset = record.offset(); // <b class="conum">(4)</b>

        kafkaConsumer.commitSync(Collections.singletonMap( // <b class="conum">(5)</b>
            new TopicPartition(topic, partition),
            new OffsetAndMetadata(offset + 1, "my metadata")
        ));

    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing Offsets Manually with Batch</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
void receive(List&lt;ConsumerRecord&lt;String, Book&gt;&gt; records, Consumer kafkaConsumer) { // <b class="conum">(2)</b>

    for (int i = 0; i &lt; records.size(); i++) {
        ConsumerRecord&lt;String, Book&gt; record = records.get(i) // <b class="conum">(3)</b>

        // process the book
        Book book = record.value()

        // commit offsets
        String topic = record.topic()
        int partition = record.partition()
        long offset = record.offset() // <b class="conum">(4)</b>

        kafkaConsumer.commitSync(Collections.singletonMap( // <b class="conum">(5)</b>
                new TopicPartition(topic, partition),
                new OffsetAndMetadata(offset + 1, "my metadata")
        ))
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Committing Offsets Manually with Batch</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(offsetReset = OffsetReset.EARLIEST, offsetStrategy = OffsetStrategy.DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
fun receive(records: List&lt;ConsumerRecord&lt;String?, Book?&gt;&gt;, kafkaConsumer: Consumer&lt;*, *&gt;) { // <b class="conum">(2)</b>
    for (i in records.indices) {
        val record = records[i] // <b class="conum">(3)</b>

        // process the book
        val book = record.value()

        // commit offsets
        val topic = record.topic()
        val partition = record.partition()
        val offset = record.offset() // <b class="conum">(4)</b>
        kafkaConsumer.commitSync(
            Collections.singletonMap( // <b class="conum">(5)</b>
                TopicPartition(topic, partition),
                OffsetAndMetadata(offset + 1, "my metadata")
            )
        )
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Committing offsets automatically is disabled</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The method receives the batch of books as a list of consumer records</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Each record is processed</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The offset, partition and topic is read for the record</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Offsets are committed</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This example is fairly trivial in that it commits offsets after processing each record in a batch, but you can for example commit after processing every 10, or every 100 or whatever makes sense for your application.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_receiving_a_consumerrecords">Receiving a ConsumerRecords</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When batching you can receive the entire <code>ConsumerRecords</code> object being listened for. In this case you should specify appropriate generic types for the key and value of the <code>ConsumerRecords</code> so that Micronaut can pick the correct deserializer for each.</p>
</div>
<div class="paragraph">
<p>This is useful when the need is to process or commit the records by partition, as the <code>ConsumerRecords</code> object already groups records by partition:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Commit only once for each partition</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
public void receiveConsumerRecords(ConsumerRecords&lt;String, Book&gt; consumerRecords, Consumer kafkaConsumer) { // <b class="conum">(2)</b>
    for (TopicPartition partition : consumerRecords.partitions()) { // <b class="conum">(3)</b>
        long offset = Long.MIN_VALUE;
        // process partition records
        for (ConsumerRecord&lt;String, Book&gt; record : consumerRecords.records(partition)) { // <b class="conum">(4)</b>
            // process the book
            Book book = record.value();
            // keep last offset
            offset = record.offset(); // <b class="conum">(5)</b>
        }

        // commit partition offset
        kafkaConsumer.commitSync(Collections.singletonMap( // <b class="conum">(6)</b>
            partition,
            new OffsetAndMetadata(offset + 1, "my metadata")
        ));
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Commit only once for each partition</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(offsetReset = EARLIEST, offsetStrategy = DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
void receiveConsumerRecords(ConsumerRecords&lt;String, Book&gt; consumerRecords, Consumer kafkaConsumer) { // <b class="conum">(2)</b>
    for (TopicPartition partition : consumerRecords.partitions()) { // <b class="conum">(3)</b>
        long offset = Long.MIN_VALUE;
        // process partition records
        for (ConsumerRecord&lt;String, Book&gt; record : consumerRecords.records(partition)) { // <b class="conum">(4)</b>
            // process the book
            Book book = record.value();
            // keep last offset
            offset = record.offset(); // <b class="conum">(5)</b>
        }

        // commit partition offset
        kafkaConsumer.commitSync(Collections.singletonMap( // <b class="conum">(6)</b>
                partition,
                new OffsetAndMetadata(offset + 1, "my metadata")
        ));
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Commit only once for each partition</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(offsetReset = OffsetReset.EARLIEST, offsetStrategy = OffsetStrategy.DISABLED, batch = true) // <b class="conum">(1)</b>
@Topic("all-the-books")
fun receiveConsumerRecords(consumerRecords: ConsumerRecords&lt;String?, Book?&gt;, kafkaConsumer: Consumer&lt;*, *&gt;) { // <b class="conum">(2)</b>
    for (partition in consumerRecords.partitions()) { // <b class="conum">(3)</b>
        var offset = Long.MIN_VALUE
        // process partition records
        for (record in consumerRecords.records(partition)) { // <b class="conum">(4)</b>
            // process the book
            val book = record.value()
            // keep last offset
            offset = record.offset() // <b class="conum">(5)</b>
        }

        // commit partition offset
        kafkaConsumer.commitSync(
            Collections.singletonMap( // <b class="conum">(6)</b>
                partition,
                OffsetAndMetadata(offset + 1, "my metadata")
            )
        )
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Committing offsets automatically is disabled</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The method receives the batch of books as a <code>ConsumerRecords</code> holder object</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Each partition is iterated over</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Each record for the partition is processed</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>The last read offset for the partition is stored</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>The offset is committed once for each partition</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_reactive_batch_processing">Reactive Batch Processing</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Batch listeners also support defining reactive types (Reactor <code>Flux</code> or RxJava <a href="http://reactivex.io/RxJava/2.x/javadoc/io/reactivex/Flowable.html">Flowable</a>) as the method argument.</p>
</div>
<div class="paragraph">
<p>Add the library <a href="https://micronaut-projects.github.io/micronaut-reactor/latest/guide/">Micronaut Reactor</a> or <a href="https://micronaut-projects.github.io/micronaut-rxjava3/latest/guide/">Micronaut RxJava 3</a> to your application&#8217;s dependencies.</p>
</div>
<div class="paragraph">
<p>In this case the method will be passed a reactive type that can be returned from the method allowing non-blocking processing of the batch:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Reactive Processing of Batch Records</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic("all-the-books")
public Flux&lt;Book&gt; receiveFlux(Flux&lt;Book&gt; books) {
    return books.doOnNext(book -&gt;
        LOG.info("Got Book = {}", book.title())
    );
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Reactive Processing of Batch Records</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic("all-the-books")
Flux&lt;Book&gt; receiveFlux(Flux&lt;Book&gt; books) {
    books.doOnNext(book -&gt;
        log.info("Got Book = {}", book.title)
    )
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Reactive Processing of Batch Records</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic("all-the-books")
fun receiveFlux(books: Flux&lt;Book&gt;): Flux&lt;Book&gt; {
    return books.doOnNext { book: Book -&gt;
        LOG.info("Got Book = {}", book.title)
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Remember that as with non batch processing, the reactive type will be subscribed to on a different thread and offsets will be committed automatically likely prior to the point when the reactive type is subscribed to.</p>
</div>
<div class="paragraph">
<p>This means that you should only use reactive processing if message durability is not a requirement and you may wish to implement message re-delivery upon failure.</p>
</div>
</div>
</div>

<h2 id="kafkaSendTo"><a class="anchor" href="#kafkaSendTo"></a>6.6 Forwarding Messages with @SendTo</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaSendTo.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>On any <code>@KafkaListener</code> method that returns a value, you can use the <a href="https://docs.micronaut.io/latest/api/io/micronaut/messaging/annotation/SendTo.html">@SendTo</a> annotation to forward the return value to the topic or topics specified by the <code>@SendTo</code> annotation.</p>
</div>
<div class="paragraph">
<p>The key of the original <code>ConsumerRecord</code> will be used as the key when forwarding the message.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Forwarding with @SendTo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic("sendto-products") // <b class="conum">(1)</b>
@SendTo("product-quantities") // <b class="conum">(2)</b>
public int receive(@KafkaKey String brand, Product product) {
    LOG.info("Got Product - {} by {}", product.name(), brand);
    return product.quantity(); // <b class="conum">(3)</b>
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Forwarding with @SendTo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic("sendto-products") // <b class="conum">(1)</b>
@SendTo("product-quantities") // <b class="conum">(2)</b>
int receive(@KafkaKey String brand, Product product) {
    log.info("Got Product - {} by {}", product.name, brand)
    product.quantity // <b class="conum">(3)</b>
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Forwarding with @SendTo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic("sendto-products") // <b class="conum">(1)</b>
@SendTo("product-quantities") // <b class="conum">(2)</b>
fun receive(@KafkaKey brand: String?, product: Product): Int {
    LOG.info("Got Product - {} by {}", product.name, brand)
    return product.quantity // <b class="conum">(3)</b>
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The topic subscribed to is <code>awesome-products</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The topic to send the result to is <code>product-quantities</code></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The return value is used to indicate the value to forward</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can also do the same using Reactive programming:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Forwarding Reactively with @SendTo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Topic("sendto-products") // <b class="conum">(1)</b>
@SendTo("product-quantities") // <b class="conum">(2)</b>
public Mono&lt;Integer&gt; receiveProduct(@KafkaKey String brand,
                                    Mono&lt;Product&gt; productSingle) {

    return productSingle.map(product -&gt; {
        LOG.info("Got Product - {} by {}", product.name(), brand);
        return product.quantity(); // <b class="conum">(3)</b>
    });
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Forwarding Reactively with @SendTo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Topic("sendto-products") // <b class="conum">(1)</b>
@SendTo("product-quantities") // <b class="conum">(2)</b>
Mono&lt;Integer&gt; receiveProduct(@KafkaKey String brand, Mono&lt;Product&gt; productSingle) {
    productSingle.map(product -&gt; {
        log.info("Got Product - {} by {}", product.name, brand)
        product.quantity // <b class="conum">(3)</b>
    })
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Forwarding Reactively with @SendTo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Topic("sendto-products") // <b class="conum">(1)</b>
@SendTo("product-quantities") // <b class="conum">(2)</b>
fun receiveProduct(@KafkaKey brand: String?, productSingle: Mono&lt;Product&gt;): Mono&lt;Int&gt; {
    return productSingle.map(Function&lt;Product, Int&gt; { product: Product -&gt;
        LOG.info("Got Product - {} by {}", product.name, brand)
        product.quantity // <b class="conum">(3)</b>
    })
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The topic subscribed to is <code>awesome-products</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The topic to send the result to is <code>product-quantities</code></td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>The return is mapped from the single to the value of the quantity</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the reactive case the <code>poll</code> loop will continue and will not wait for the record to be sent unless you specifically annotate the method with <a href="../api/io/micronaut/core/annotation/Blocking.html">@Blocking</a>.</p>
</div>
<div class="paragraph">
<p>To enable transactional sending of the messages you need to define <code>producerTransactionalId</code> in <code>@KafkaListener</code>.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Transactional consumer-producer</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(
    offsetReset = OffsetReset.EARLIEST,
    producerClientId = "word-counter-producer", // <b class="conum">(1)</b>
    producerTransactionalId = "tx-word-counter-id", // <b class="conum">(2)</b>
    offsetStrategy = OffsetStrategy.SEND_TO_TRANSACTION, // <b class="conum">(3)</b>
    isolation = IsolationLevel.READ_COMMITTED // <b class="conum">(4)</b>
)
public class WordCounter {

    @Topic("tx-incoming-strings")
    @SendTo("my-words-count")
    List&lt;KafkaMessage&lt;byte[], Integer&gt;&gt; wordsCounter(String string) {
        return Stream.of(string.split("\\s+"))
            .collect(Collectors.groupingBy(Function.identity(), Collectors.summingInt(i -&gt; 1)))
            .entrySet()
            .stream()
            .map(e -&gt; KafkaMessage.Builder.&lt;byte[], Integer&gt;withBody(e.getValue()).key(e.getKey().getBytes()).build())
            .toList();
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Transactional consumer-producer</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(
        offsetReset = OffsetReset.EARLIEST,
        producerClientId = 'word-counter-producer', // <b class="conum">(1)</b>
        producerTransactionalId = 'tx-word-counter-id', // <b class="conum">(2)</b>
        offsetStrategy = OffsetStrategy.SEND_TO_TRANSACTION, // <b class="conum">(3)</b>
        isolation = IsolationLevel.READ_COMMITTED // <b class="conum">(4)</b>
)
class WordCounter {

    @Topic('tx-incoming-strings')
    @SendTo('my-words-count')
    List&lt;KafkaMessage&lt;byte[], Integer&gt;&gt; wordsCounter(String string) {
        string.split("\\s+")
            .groupBy()
            .collect { key, instanceList -&gt;
                KafkaMessage.Builder.withBody(instanceList.size()).key(key.bytes).build()
            }
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Transactional consumer-producer</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(
    offsetReset = OffsetReset.EARLIEST,
    producerClientId = "word-counter-producer", // <b class="conum">(1)</b>
    producerTransactionalId = "tx-word-counter-id", // <b class="conum">(2)</b>
    offsetStrategy = OffsetStrategy.SEND_TO_TRANSACTION, // <b class="conum">(3)</b>
    isolation = IsolationLevel.READ_COMMITTED // <b class="conum">(4)</b>
)
class WordCounter {

    @Topic("tx-incoming-strings")
    @SendTo("my-words-count")
    fun wordsCounter(string: String) = string
        .split(Regex("\\s+"))
        .groupBy { it }
        .map { KafkaMessage.Builder.withBody&lt;ByteArray, Int&gt;(it.value.size).key(it.key.toByteArray()).build() }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>The id of the producer to load additional config properties</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The transactional id that is required to enable transactional processing</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Enable offset strategy to commit the offsets to the transaction</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Consumer read messages isolation</td>
</tr>
</table>
</div>

<h2 id="kafkaErrors"><a class="anchor" href="#kafkaErrors"></a>6.7 Handling Consumer Exceptions</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaListener/kafkaErrors.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="sect2">
<h3 id="_consumer_error_strategies">Consumer error strategies</h3>
<div class="paragraph">
<p>It&#8217;s possible to define a different error strategy for <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> using <code>errorStrategy</code> attribute:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying an error strategy</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(
    value = "myGroup",
    errorStrategy = @ErrorStrategy(
        value = ErrorStrategyValue.RETRY_ON_ERROR,
        retryDelay = "50ms",
        retryCount = 3
    )
)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying an error strategy</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(
    value = 'myGroup',
    errorStrategy = @ErrorStrategy(
            value = ErrorStrategyValue.RETRY_ON_ERROR,
            retryDelay = '50ms',
            retryCount = 3
    )
)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying an error strategy</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(
    value = "myGroup",
    errorStrategy = ErrorStrategy(
        value = ErrorStrategyValue.RETRY_ON_ERROR,
        retryDelay = "50ms",
        retryCount = 3
    )
)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Setting the error strategy allows you to resume at the next offset or to seek the consumer (stop on error) to the failed offset so that it can retry if an error occurs.</p>
</div>
<div class="paragraph">
<p>You can choose one of the error strategies:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>RETRY_ON_ERROR</code> - This strategy will stop consuming subsequent records in the case of an error and by default will attempt to re-consume the current record once. Possible retry delay can be defined by <code>retryDelay</code> and retry count by <code>retryCount</code>.</p>
</li>
<li>
<p><code>RETRY_EXPONENTIALLY_ON_ERROR</code> - This strategy will stop consuming subsequent records in the case of an error and by default will attempt to re-consume the current record once. The exponentially growing time breaks between consumption attempts is computed using the <code>n * 2^(k - 1)</code> formula where the initial delay <code>n</code> is <code>retryDelay</code> and the number of retries is <code>retryCount</code>.</p>
</li>
<li>
<p><code>RETRY_CONDITIONALLY_ON_ERROR</code> - This strategy will stop consuming subsequent records in the case of an error and by default will attempt to re-consume the current record once. The retry behaviour can be overridden. Possible retry delay can be defined by <code>retryDelay</code> and retry count by <code>retryCount</code>.</p>
</li>
<li>
<p><code>RETRY_CONDITIONALLY_EXPONENTIALLY_ON_ERROR</code> - This strategy will stop consuming subsequent records in the case of an error and by default will attempt to re-consume the current record once. The retry behaviour can be overridden. The exponentially growing time breaks between consumption attempts is computed using the <code>n * 2^(k - 1)</code> formula where the initial delay <code>n</code> is <code>retryDelay</code> and the number of retries is <code>retryCount</code>.</p>
</li>
<li>
<p><code>RESUME_AT_NEXT_RECORD</code> - This strategy will ignore the current error and will resume at the next offset, in this case it&#8217;s recommended to have a custom exception handler that moves the failed message into an error queue.</p>
</li>
<li>
<p><code>NONE</code> - This error strategy will skip over all records from the current offset in the current poll when the consumer encounters an error. This option is deprecated and kept for consistent behaviour with previous versions of Micronaut Kafka that do not support error strategy.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The error strategies apply only for non-batch messages processing.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
When using retry error strategies in combination with reactive consumer methods, it is necessary to add the <code>@Blocking</code> annotation to the reactive consumer method.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can also make the number of retries configurable by using <code>retryCountValue</code>:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Dynamically Configuring Retries</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(
    value = "myGroup",
    errorStrategy = @ErrorStrategy(
        value = ErrorStrategyValue.RETRY_ON_ERROR,
        retryCountValue = "${my.retry.count}"
    )
)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Dynamically Configuring Retries</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(
    value = 'myGroup',
    errorStrategy = @ErrorStrategy(
            value = ErrorStrategyValue.RETRY_ON_ERROR,
            retryCountValue = '${my.retry.count}'
    )
)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Dynamically Configuring Retries</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(
    value = "myGroup",
    errorStrategy = ErrorStrategy(
        value = ErrorStrategyValue.RETRY_ON_ERROR,
        retryCountValue = "\${my.retry.count}"
    )
)</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>retryCountValue</code> will be overridden by <code>retryCount</code> if they are both set.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_specify_exceptions_to_retry">Specify exceptions to retry</h4>
<div class="paragraph">
<p>It&#8217;s possible to define only exceptions from which the retry will occur.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying exceptions to retry</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(
        value = "myGroup",
        errorStrategy = @ErrorStrategy(
                value = ErrorStrategyValue.RETRY_ON_ERROR,
                retryDelay = "50ms",
                retryCount = 3,
                exceptionTypes = { MyException.class, MySecondException.class }
        )
)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying exceptions to retry</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(
    value = 'myGroup',
    errorStrategy = @ErrorStrategy(
            value = ErrorStrategyValue.RETRY_ON_ERROR,
            retryDelay = '50ms',
            retryCount = 3,
            exceptionTypes = [ MyException, MySecondException ]
    )
)</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying exceptions to retry</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(
    value = "myGroup",
    errorStrategy = ErrorStrategy(
        value = ErrorStrategyValue.RETRY_ON_ERROR,
        retryDelay = "50ms",
        retryCount = 3,
        exceptionTypes = [MyException::class, MySecondException::class]
    )
)</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Specify exception to retry apply only for <code>RETRY_ON_ERROR</code> and <code>RETRY_EXPONENTIALLY_ON_ERROR</code> error strategies.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_conditional_retries">Conditional retries</h4>
<div class="paragraph">
<p>It is possible to conditionally retry a message based on the exception thrown when the error strategy is <code>RETRY_CONDITIONALLY_ON_ERROR</code> or <code>RETRY_CONDITIONALLY_EXPONENTIALLY_ON_ERROR</code>.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying conditional retry behaviour on the listener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@KafkaListener(
    value = "myGroup",
    errorStrategy = @ErrorStrategy(
        value = ErrorStrategyValue.RETRY_CONDITIONALLY_ON_ERROR
    )
)
public class ConditionalRetryListener implements ConditionalRetryBehaviourHandler {

    @Override
    public ConditionalRetryBehaviour conditionalRetryBehaviour(KafkaListenerException exception) {
        return shouldRetry(exception) ? ConditionalRetryBehaviour.RETRY : ConditionalRetryBehaviour.SKIP;
    }

    // ...</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying conditional retry behaviour on the listener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@KafkaListener(
    value = 'myGroup',
    errorStrategy = @ErrorStrategy(
            value = ErrorStrategyValue.RETRY_CONDITIONALLY_ON_ERROR
    )
)
class ConditionalRetryListener implements ConditionalRetryBehaviourHandler {
    @Override
    ConditionalRetryBehaviour conditionalRetryBehaviour(KafkaListenerException exception) {
        return shouldRetry(exception) ? ConditionalRetryBehaviour.RETRY : ConditionalRetryBehaviour.SKIP
    }

    // ...</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Specifying conditional retry behaviour on the listener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@KafkaListener(
    value = "myGroup",
    errorStrategy = ErrorStrategy(
        value = ErrorStrategyValue.RETRY_CONDITIONALLY_ON_ERROR
    )
)
class ConditionalRetryListener :
    ConditionalRetryBehaviourHandler {
    override fun conditionalRetryBehaviour(exception: KafkaListenerException): ConditionalRetryBehaviour {
        return if (shouldRetry(exception)) {
            ConditionalRetryBehaviour.RETRY
        } else {
            ConditionalRetryBehaviour.SKIP
        }
    }

    // ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>When a <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> does not implement <a href="../api/io/micronaut/configuration/kafka/retry/ConditionalRetryBehaviourHandler.html">@ConditionalRetryBehaviourHandler</a>, the <a href="../api/io/micronaut/configuration/kafka/exceptions/DefaultConditionalRetryBehaviourHandler.html">@DefaultConditionalRetryBehaviourHandler</a> will be used and all messages that failed processing will be retried.</p>
</div>
<div class="paragraph">
<p>If you wish to apply the same conditional retry strategy for all of your <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> you can define a bean that implements <code>ConditionalRetryBehaviourHandler</code> and use Micronaut&#8217;s <a href="https://docs.micronaut.io/latest/guide/#replaces">Bean Replacement</a> feature to replace the default bean: <code>@Replaces(DefaultConditionalRetryBehaviourHandler.class)</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Conditional retry behaviour only applies to <code>RETRY_CONDITIONALLY_ON_ERROR</code> and <code>RETRY_CONDITIONALLY_EXPONENTIALLY_ON_ERROR</code> error strategies.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_exception_handlers">Exception handlers</h3>
<div class="paragraph">
<p>When an exception occurs in a <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> method by default the exception is simply logged. This is handled by <a href="../api/io/micronaut/configuration/kafka/exceptions/DefaultKafkaListenerExceptionHandler.html">DefaultKafkaListenerExceptionHandler</a>.</p>
</div>
<div class="paragraph">
<p>The following options are available to configure the default Kafka listener exception handler:</p>
</div>
<a id="io.micronaut.configuration.kafka.config.DefaultKafkaListenerExceptionHandlerConfigurationProperties" href="#io.micronaut.configuration.kafka.config.DefaultKafkaListenerExceptionHandlerConfigurationProperties">&#128279;</a>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Configuration Properties for <a href="../api/io/micronaut/configuration/kafka/config/DefaultKafkaListenerExceptionHandlerConfigurationProperties.html">DefaultKafkaListenerExceptionHandlerConfigurationProperties</a></caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Property</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>kafka.default-listener-exception-handler.skip-record-on-deserialization-failure</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether to skip record on deserialization failure. Default value true</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>kafka.default-listener-exception-handler.commit-record-on-deserialization-failure</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether to commit record on deserialization failure. Default value false</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>If you wish to replace this default exception handling with another implementation you can use the Micronaut&#8217;s <a href="https://docs.micronaut.io/latest/guide/#replaces">Bean Replacement</a> feature to define a bean that replaces it: <code>@Replaces(DefaultKafkaListenerExceptionHandler.class)</code>.</p>
</div>
<div class="paragraph">
<p>You can also define per bean exception handling logic by implementing the <a href="../api/io/micronaut/configuration/kafka/exceptions/KafkaListenerExceptionHandler.html">KafkaListenerExceptionHandler</a> interface in your <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> class.</p>
</div>
<div class="paragraph">
<p>The <a href="../api/io/micronaut/configuration/kafka/exceptions/KafkaListenerExceptionHandler.html">KafkaListenerExceptionHandler</a> receives an exception of type <a href="../api/io/micronaut/configuration/kafka/exceptions/KafkaListenerException.html">KafkaListenerException</a> which allows access to the original <code>ConsumerRecord</code>, if available.</p>
</div>
</div>

<h1 id="kafkaApplications"><a class="anchor" href="#kafkaApplications"></a>7 Running Kafka Applications</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaApplications.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>You can run a Micronaut Kafka application with or without the presence of an HTTP server.</p>
</div>
<div class="paragraph">
<p>If you run your application without the <code>http-server-netty</code> dependency you will see output like the following on startup:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">11:06:22.638 [main] INFO  io.micronaut.runtime.Micronaut - Startup completed in 402ms. Server Running: 4 active message listeners.</code></pre>
</div>
</div>
<div class="paragraph">
<p>No port is exposed, but the Kafka consumers are active and running. The process registers a shutdown hook such that the <code>KafkaConsumer</code> instances are closed correctly when the server is shutdown.</p>
</div>

<h2 id="kafkaHealth"><a class="anchor" href="#kafkaHealth"></a>7.1 Kafka Health Checks</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaApplications/kafkaHealth.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>In addition to <code>http-server-netty</code>, if the <code>management</code> dependency is added, then Micronaut&#8217;s <a href="https://docs.micronaut.io/latest/guide/#healthEndpoint">Health Endpoint</a> can be used to expose the health status of the Kafka consumer application.</p>
</div>
<div class="paragraph">
<p>For example if Kafka is not available the <code>/health</code> endpoint will return:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
    "status": "DOWN",
    "details": {
        ...
        "kafka": {
            "status": "DOWN",
            "details": {
                "error": "java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.TimeoutException: Timed out waiting for a node assignment."
            }
        }
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
By default, the details visible above are only shown to authenticated users. See the <a href="https://docs.micronaut.io/latest/guide/#healthEndpoint">Health Endpoint</a> documentation for how to configure that setting.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The following options are available to configure the Kafka Health indicator:</p>
</div>
<a id="io.micronaut.configuration.kafka.config.KafkaHealthConfigurationProperties" href="#io.micronaut.configuration.kafka.config.KafkaHealthConfigurationProperties">&#128279;</a>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Configuration Properties for <a href="../api/io/micronaut/configuration/kafka/config/KafkaHealthConfigurationProperties.html">KafkaHealthConfigurationProperties</a></caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Property</th>
<th class="tableblock halign-left valign-top">Type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>kafka.health-timeout</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">java.time.Duration</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The health check timeout.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>kafka.health.enabled</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Whether the Kafka health check is enabled. Default value true.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>kafka.health.restricted</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">By default, the health check requires cluster-wide permissions in order to get information about the nodes in the Kafka cluster. If your application doesn&#8217;t have admin privileges (for example, this might happen in multi-tenant scenarios), you can switch to a "restricted" version of the health check which only validates basic connectivity but doesn&#8217;t require any additional permissions.. Default value false</p></td>
</tr>
</tbody>
</table>

<h2 id="kafkaMetrics"><a class="anchor" href="#kafkaMetrics"></a>7.2 Kafka Metrics</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaApplications/kafkaMetrics.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>You can enable Kafka Metrics collection by enabling <a href="https://micronaut-projects.github.io/micronaut-micrometer/latest/guide">Micrometer Metrics</a>.</p>
</div>
<div class="paragraph">
<p>If you do not wish to collect Kafka metrics, you can set <code>micronaut.metrics.binders.kafka.enabled</code> to <code>false</code> in <code>application.yml</code>.
In the case of Kafka Streams metrics, you can use <code>micronaut.metrics.binders.kafka.streams.enabled</code> instead.</p>
</div>

<h2 id="kafkaTracing"><a class="anchor" href="#kafkaTracing"></a>7.3 Kafka Distributed Tracing</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaApplications/kafkaTracing.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>Distributed tracing is supported via the <a href="https://micronaut-projects.github.io/micronaut-tracing/latest/guide">Micronaut Tracing</a> module <a href="https://micronaut-projects.github.io/micronaut-tracing/latest/guide/#kafka">using Open Telemetry</a>.</p>
</div>

<h2 id="kafkaNewTopics"><a class="anchor" href="#kafkaNewTopics"></a>7.4 Creating New Topics</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaApplications/kafkaNewTopics.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>You can automatically add topics to the broker when your application starts. To do so, add a bean of type a <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/admin/NewTopic"><code>NewTopic</code></a> for each topic you want to create. <code>NewTopic</code> instances let you specify the name, the number of partitions, the replication factor, the replicas assignments and the configuration properties you want to associate with the new topic. Additionally, you can add a bean of type <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/admin/CreateTopicsOptions"><code>CreateTopicsOptions</code></a> that will be used when the new topics are created.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Creating New Kafka Topics with Options</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.context.annotation.Bean;
import io.micronaut.context.annotation.Factory;
import io.micronaut.context.annotation.Requires;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.CreateTopicsOptions;
import org.apache.kafka.clients.admin.NewTopic;

@Requires(bean = AdminClient.class)
@Factory
public class MyTopicFactory {

    @Bean
    CreateTopicsOptions options() {
        return new CreateTopicsOptions().timeoutMs(5000).validateOnly(true).retryOnQuotaViolation(false);
    }

    @Bean
    NewTopic topic1() {
        return new NewTopic("my-new-topic-1", 1, (short) 1);
    }

    @Bean
    NewTopic topic2() {
        return new NewTopic("my-new-topic-2", 2, (short) 1);
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Creating New Kafka Topics with Options</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.context.annotation.Bean
import io.micronaut.context.annotation.Factory
import io.micronaut.context.annotation.Requires
import org.apache.kafka.clients.admin.AdminClient
import org.apache.kafka.clients.admin.CreateTopicsOptions
import org.apache.kafka.clients.admin.NewTopic

@Requires(bean = AdminClient)
@Factory
class MyTopicFactory {

    @Bean
    CreateTopicsOptions options() {
        new CreateTopicsOptions().timeoutMs(5000).validateOnly(true).retryOnQuotaViolation(false)
    }

    @Bean
    NewTopic topic1() {
        new NewTopic("my-new-topic-1", 1, (short) 1)
    }

    @Bean
    NewTopic topic2() {
        new NewTopic("my-new-topic-2", 2, (short) 1)
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Creating New Kafka Topics with Options</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.context.annotation.Bean
import io.micronaut.context.annotation.Factory
import io.micronaut.context.annotation.Requires
import org.apache.kafka.clients.admin.AdminClient
import org.apache.kafka.clients.admin.CreateTopicsOptions
import org.apache.kafka.clients.admin.NewTopic

@Requires(bean = AdminClient::class)
@Factory
class MyTopicFactory {

    @Bean
    fun options(): CreateTopicsOptions {
        return CreateTopicsOptions().timeoutMs(5000).validateOnly(true).retryOnQuotaViolation(false)
    }

    @Bean
    fun topic1(): NewTopic {
        return NewTopic("my-new-topic-1", 1, 1)
    }

    @Bean
    fun topic2(): NewTopic {
        return NewTopic("my-new-topic-2", 2, 1)
    }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Creating topics is not a transactional operation, so it may succeed for some topics while fail for others. This operation also executes asynchronously, so it may take several seconds until all the brokers become aware that the topics have been created.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you ever need to check if the operation has completed, you can <code>@Inject</code> or retrieve the <a href="../api/io/micronaut/configuration/kafka/admin/KafkaNewTopics.html">KafkaNewTopics</a> bean from the application context and then retrieve the <a href="https://kafka.apache.org/27/javadoc//org/apache/kafka/clients/admin/CreateTopicsResult">operation result</a> that Kafka returned when the topics were created.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Checking if Topic Creation is Done</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">    boolean areNewTopicsDone(KafkaNewTopics newTopics) {
        return newTopics.getResult().all().isDone();
    }</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Checking if Topic Creation is Done</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">    boolean areNewTopicsDone(KafkaNewTopics newTopics) {
        newTopics.result.all().done
    }</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Checking if Topic Creation is Done</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">    fun areNewTopicsDone(newTopics: KafkaNewTopics): Boolean {
        return newTopics.result.all().isDone
    }</code></pre>
</div>
</div>

<h2 id="kafkaDisabled"><a class="anchor" href="#kafkaDisabled"></a>7.5 Disabling Micronaut-Kafka</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaApplications/kafkaDisabled.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>If you want to disable micronaut-kafka entirely, you can set <code>kafka.enabled</code> to <code>false</code> in <code>application.yml</code>.</p>
</div>
<div class="paragraph">
<p>This will prevent the instantiation of all kafka-related beans.</p>
</div>
<div class="paragraph">
<p>You must, however, provide your own replacement implementations of any <code>@KafkaClient</code> interfaces:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Creating Replacement KafkaClient Implementations</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.context.annotation.Replaces;
import io.micronaut.context.annotation.Requires;
import io.micronaut.core.util.StringUtils;
import jakarta.inject.Singleton;

@Requires(property = "kafka.enabled", notEquals = StringUtils.TRUE, defaultValue = StringUtils.TRUE) // <b class="conum">(1)</b>
@Replaces(MessageClient.class) // <b class="conum">(2)</b>
@Singleton
public class MessageClientFallback implements MessageClient { // <b class="conum">(3)</b>

    @Override
    public void send(String message) {
        throw new UnsupportedOperationException(); // <b class="conum">(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Creating Replacement KafkaClient Implementations</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.context.annotation.Replaces
import io.micronaut.context.annotation.Requires
import io.micronaut.core.util.StringUtils
import jakarta.inject.Singleton

@Requires(property = 'kafka.enabled', notEquals = StringUtils.TRUE, defaultValue = StringUtils.TRUE) // <b class="conum">(1)</b>
@Replaces(MessageClient.class) // <b class="conum">(2)</b>
@Singleton
class MessageClientFallback implements MessageClient { // <b class="conum">(3)</b>

    @Override
    void send(String message) {
        throw new UnsupportedOperationException() // <b class="conum">(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Creating Replacement KafkaClient Implementations</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.context.annotation.Replaces
import io.micronaut.context.annotation.Requires
import io.micronaut.core.util.StringUtils
import jakarta.inject.Singleton

@Requires(property = "kafka.enabled", notEquals = StringUtils.TRUE, defaultValue = StringUtils.TRUE) // <b class="conum">(1)</b>
@Replaces(MessageClient::class) // <b class="conum">(2)</b>
@Singleton
class MessageClientFallback : MessageClient { // <b class="conum">(3)</b>

    override fun send(message: String) {
        throw UnsupportedOperationException() // <b class="conum">(4)</b>
    }
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Only instantiate when <code>kafka.enabled</code> is set to <code>false</code></td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Replace the <code>@KafkaClient</code> interface</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Implement the interface</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Provide an alternative implementation for all client methods</td>
</tr>
</table>
</div>

<h1 id="kafkaStreams"><a class="anchor" href="#kafkaStreams"></a>8 Kafka Streams</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaStreams.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="title">Using the CLI</div>
<div class="paragraph">
<p>If you are creating your project using the Micronaut CLI, supply the <code>kafka-streams</code> feature to include a simple Kafka Streams configuration in your project:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ mn create-app my-app --features kafka-streams</pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><a href="https://kafka.apache.org/documentation/streams/">Kafka Streams</a> is a platform for building real time streaming applications.</p>
</div>
<div class="paragraph">
<p>When using Micronaut with Kafka Stream, your application gains all of the features from Micronaut (configuration management, AOP, DI, health checks etc.), simplifying the construction of Kafka Stream applications.</p>
</div>
<div class="paragraph">
<p>Since Micronaut&#8217;s DI and AOP is compile time, you can build low overhead stream applications with ease.</p>
</div>
<div class="sect1">
<h2 id="_defining_kafka_streams">Defining Kafka Streams</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To define Kafka Streams you should first add the <code>kafka-streams</code> configuration to your build.</p>
</div>
<div class="paragraph">
<p>        <div class="listingblock multi-language-sample">
<div class="title"></div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="gradle">implementation(<span class="hljs-string">"io.micronaut.kafka:micronaut-kafka-streams")</span></code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="maven">&lt;dependency&gt;
    &lt;groupId&gt;io.micronaut.kafka&lt;/groupId&gt;
    &lt;artifactId&gt;micronaut-kafka-streams&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre>
</div>
</div></p>
</div>
<div class="paragraph">
<p>The minimum configuration required is to set the Kafka bootstrap servers:</p>
</div>
<div class="openblock">
<div class="title">Configuring Kafka</div>
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.bootstrap.servers=localhost:9092</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    bootstrap:
        servers: localhost:9092</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.bootstrap]
    servers="localhost:9092"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  bootstrap {
    servers = "localhost:9092"
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    bootstrap {
      servers = "localhost:9092"
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "bootstrap": {
      "servers": "localhost:9092"
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You should then define a <a href="../api/io/micronaut/context/annotation/Factory.html">@Factory</a> for your streams that defines beans that return a <code>KStream</code>. For example to implement the Word Count example from the Kafka Streams documentation:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Kafka Streams Word Count</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.streams.ConfiguredStreamBuilder;
import io.micronaut.context.annotation.Factory;
import io.micronaut.context.annotation.Requires;
import jakarta.inject.Named;
import jakarta.inject.Singleton;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.Grouped;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Produced;

import java.util.Arrays;
import java.util.Locale;
import java.util.Properties;

@Factory
public class WordCountStream {

    @Singleton
    @Named("word-count")
    KStream&lt;String, String&gt; wordCountStream(ConfiguredStreamBuilder builder) { // <b class="conum">(1)</b>
        // set default serdes
        Properties props = builder.getConfiguration();
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, "500");

        KStream&lt;String, String&gt; source = builder.stream("streams-plaintext-input"); // <b class="conum">(2)</b>

        KTable&lt;String, Long&gt; groupedByWord = source
            .flatMapValues(value -&gt; Arrays.asList(value.toLowerCase().split("\\W+")))
            .groupBy((key, word) -&gt; word, Grouped.with(Serdes.String(), Serdes.String()))
            //Store the result in a store for lookup later
            .count(Materialized.as("word-count-store-java")); // <b class="conum">(3)</b>

        groupedByWord
            //convert to stream
            .toStream()
            //send to output using specific serdes
            .to("streams-wordcount-output", Produced.with(Serdes.String(), Serdes.Long())); // <b class="conum">(4)</b>

        return source;
    }</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Kafka Streams Word Count</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.streams.ConfiguredStreamBuilder
import io.micronaut.context.annotation.Factory
import io.micronaut.context.annotation.Requires
import jakarta.inject.Named
import jakarta.inject.Singleton
import org.apache.kafka.clients.consumer.ConsumerConfig
import org.apache.kafka.common.serialization.Serdes
import org.apache.kafka.streams.StreamsConfig
import org.apache.kafka.streams.kstream.Grouped
import org.apache.kafka.streams.kstream.KStream
import org.apache.kafka.streams.kstream.KTable
import org.apache.kafka.streams.kstream.Materialized
import org.apache.kafka.streams.kstream.Produced

@Factory
class WordCountStream {

    @Singleton
    @Named('word-count')
    KStream&lt;String, String&gt; wordCountStream(ConfiguredStreamBuilder builder) { // <b class="conum">(1)</b>
        // set default serdes
        Properties props = builder.getConfiguration();
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName())
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName())
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, 'earliest')
        props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, '500')

        KStream&lt;String, String&gt; source = builder.stream('streams-plaintext-input') // <b class="conum">(2)</b>

        KTable&lt;String, Long&gt; groupedByWord = source
            .flatMapValues(value -&gt; Arrays.asList(value.toLowerCase().split("\\W+")))
            .groupBy((key, word) -&gt; word, Grouped.with(Serdes.String(), Serdes.String()))
            //Store the result in a store for lookup later
            .count(Materialized.as('word-count-store-groovy')) // <b class="conum">(3)</b>

        groupedByWord
            //convert to stream
            .toStream()
            //send to output using specific serdes
            .to("streams-wordcount-output", Produced.with(Serdes.String(), Serdes.Long())) // <b class="conum">(4)</b>

        return source
    }</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Kafka Streams Word Count</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.streams.ConfiguredStreamBuilder
import io.micronaut.context.annotation.Factory
import io.micronaut.context.annotation.Requires
import jakarta.inject.Named
import jakarta.inject.Singleton
import org.apache.kafka.clients.consumer.ConsumerConfig
import org.apache.kafka.common.serialization.Serdes
import org.apache.kafka.streams.StreamsConfig
import org.apache.kafka.streams.kstream.Grouped
import org.apache.kafka.streams.kstream.KStream
import org.apache.kafka.streams.kstream.Materialized
import org.apache.kafka.streams.kstream.Produced
import java.util.*

@Factory
class WordCountStream {

    @Singleton
    @Named("word-count")
    fun wordCountStream(builder: ConfiguredStreamBuilder): KStream&lt;String, String&gt; { // <b class="conum">(1)</b>
        // set default serdes
        val props = builder.configuration
        props[StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG] = Serdes.String().javaClass.getName()
        props[StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG] = Serdes.String().javaClass.getName()
        props[ConsumerConfig.AUTO_OFFSET_RESET_CONFIG] = "earliest"
        props[StreamsConfig.COMMIT_INTERVAL_MS_CONFIG] = "500"
        val source = builder.stream&lt;String, String&gt;("streams-plaintext-input") // <b class="conum">(2)</b>
        val groupedByWord = source
            .flatMapValues { value: String -&gt;
                Arrays.asList(
                    *value.lowercase(Locale.getDefault()).split("\\W+".toRegex()).dropLastWhile { it.isEmpty() }
                        .toTypedArray())
            }
            .groupBy(
                { key: String?, word: String? -&gt; word },
                Grouped.with(Serdes.String(), Serdes.String())
            )
            //Store the result in a store for lookup later
            .count(Materialized.`as`("word-count-store-kotlin")) // <b class="conum">(3)</b>
        groupedByWord
            //convert to stream
            .toStream()
            //send to output using specific serdes
            .to("streams-wordcount-output", Produced.with(Serdes.String(), Serdes.Long())) // <b class="conum">(4)</b>
        return source
    }</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>An instance of <a href="../api/io/micronaut/configuration/kafka/streams/ConfiguredStreamBuilder.html">ConfiguredStreamBuilder</a> is injected that allows mutating the configuration</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The input topic</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Materialize the count stream and save to a state store</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>The output topic</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
With Kafka streams the key and value <code>Serdes</code> (serializer/deserializer) must be classes with a zero argument constructor. If you wish to use JSON (de)serialization you can subclass <a href="../api/io/micronaut/configuration/kafka/serde/JsonObjectSerde.html">JsonObjectSerde</a> to define your <code>Serdes</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can use the <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaClient.html">@KafkaClient</a> annotation to send a sentence to be processed by the above stream:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Defining a Kafka Client</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaClient;
import io.micronaut.configuration.kafka.annotation.Topic;
import io.micronaut.context.annotation.Requires;

@KafkaClient
public interface WordCountClient {

    @Topic("streams-plaintext-input")
    void publishSentence(String sentence);
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Defining a Kafka Client</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires

@KafkaClient
interface WordCountClient {

    @Topic("streams-plaintext-input")
    void publishSentence(String sentence)
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Defining a Kafka Client</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaClient
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires

@KafkaClient
interface WordCountClient {

    @Topic("streams-plaintext-input")
    fun publishSentence(sentence: String?)
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also define a <a href="../api/io/micronaut/configuration/kafka/annotation/KafkaListener.html">@KafkaListener</a> to listen for the result of the word count stream:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Defining a Kafka Listener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.annotation.KafkaKey;
import io.micronaut.configuration.kafka.annotation.KafkaListener;
import io.micronaut.configuration.kafka.annotation.Topic;
import io.micronaut.context.annotation.Requires;

import java.util.Collections;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

import static io.micronaut.configuration.kafka.annotation.OffsetReset.EARLIEST;

@KafkaListener(offsetReset = EARLIEST, groupId = "WordCountListener")
public class WordCountListener {

    private final Map&lt;String, Long&gt; wordCounts = new ConcurrentHashMap&lt;&gt;();

    @Topic("streams-wordcount-output")
    void count(@KafkaKey String word, long count) {
        wordCounts.put(word, count);
    }

    public long getCount(String word) {
        Long num = wordCounts.get(word);
        return num != null ? num : 0;
    }

    public Map&lt;String, Long&gt; getWordCounts() {
        return Collections.unmodifiableMap(wordCounts);
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Defining a Kafka Listener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.annotation.KafkaKey;
import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires

import java.util.concurrent.ConcurrentHashMap

import static io.micronaut.configuration.kafka.annotation.OffsetReset.EARLIEST

@KafkaListener(offsetReset = EARLIEST, groupId = 'WordCountListener')
class WordCountListener {

    private final Map&lt;String, Long&gt; wordCounts = new ConcurrentHashMap&lt;&gt;()

    @Topic("streams-wordcount-output")
    void count(@KafkaKey String word, long count) {
        wordCounts.put(word, count)
    }

    long getCount(String word) {
        Long num = wordCounts.get(word)
        num ?: 0
    }

    Map&lt;String, Long&gt; getWordCounts() {
        Collections.unmodifiableMap(wordCounts)
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Defining a Kafka Listener</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.annotation.KafkaKey
import io.micronaut.configuration.kafka.annotation.KafkaListener
import io.micronaut.configuration.kafka.annotation.OffsetReset
import io.micronaut.configuration.kafka.annotation.Topic
import io.micronaut.context.annotation.Requires
import java.util.*
import java.util.concurrent.ConcurrentHashMap

@KafkaListener(offsetReset = OffsetReset.EARLIEST, groupId = "WordCountListener")
class WordCountListener {

    private val wordCounts: MutableMap&lt;String, Long&gt; = ConcurrentHashMap()

    @Topic("streams-wordcount-output")
    fun count(@KafkaKey word: String, count: Long) {
        wordCounts[word] = count
    }

    fun getCount(word: String): Long {
        val num = wordCounts[word]
        return num ?: 0
    }

    fun getWordCounts(): Map&lt;String, Long&gt; {
        return Collections.unmodifiableMap(wordCounts)
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_configuring_kafka_streams">Configuring Kafka Streams</h2>
<div class="sectionbody">
<div class="paragraph">
<div class="title">Configuring a single Stream on a Micronaut application.</div>
<p>If you have a single Kafka Stream configured on your Micronaut service, then you should use the <code>default</code> key on the configuration.</p>
</div>
<div class="openblock">
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.streams.default.processing.guarantee=exactly_once
kafka.streams.default.auto.offset.reset=earliest</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    streams:
       default:
          processing.guarantee: "exactly_once"
          auto.offset.reset: "earliest"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.streams]
    [kafka.streams.default]
      "processing.guarantee"="exactly_once"
      "auto.offset.reset"="earliest"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  streams {
    'default' {
      processing.guarantee = "exactly_once"
      auto.offset.reset = "earliest"
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    streams {
      default {
        "processing.guarantee" = "exactly_once"
        "auto.offset.reset" = "earliest"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "streams": {
      "default": {
        "processing.guarantee": "exactly_once",
        "auto.offset.reset": "earliest"
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The above configuration example sets the <code>processing.guarantee</code> and <code>auto.offset.reset</code> setting of the <code>default</code> Stream. Most of the configuration properties pass directly through to the <code>KafkaStreams</code> instance being initialized.</p>
</div>
<div class="paragraph">
<p>In addition to those standard properties, you may want to customize how long you wait for Kafka Streams to shut down (this is mostly useful during testing), with <code>close-timeout</code>.</p>
</div>
<div class="paragraph">
<p>For example, this will make Micronaut Kafka wait for up to 10 seconds to shut down the default stream:</p>
</div>
<div class="openblock">
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.streams.default.close-timeout=10s</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    streams:
        default:
            close-timeout: 10s</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.streams]
    [kafka.streams.default]
      close-timeout="10s"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  streams {
    'default' {
      closeTimeout = "10s"
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    streams {
      default {
        close-timeout = "10s"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "streams": {
      "default": {
        "close-timeout": "10s"
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<div class="title">Configuring multiple Stream definitions on the same Micronaut Service.</div>
<p>You can define multiple Kafka Streams on the same Micronaut application, each with their own unique configuration.
To do this you should define the configuration with <code>kafka.streams.[STREAM-NAME]</code>.
Assuming you have 2 or more Kafka Streams definitions on a single service, you will need to use the <code>default</code> key for at least one of them and then define <code>kafka.streams.[STREAM-NAME]</code> for the rest.</p>
</div>
<div class="paragraph">
<p>For example in <code>application.yml</code>:</p>
</div>
<div class="openblock">
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.streams.default.num.stream.threads=1
kafka.streams.my-other-stream.num.stream.threads=10</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    streams:
        default:
          num:
            stream:
              threads: 1
        my-other-stream:
          num:
            stream:
              threads: 10</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.streams]
    [kafka.streams.default]
      [kafka.streams.default.num]
        [kafka.streams.default.num.stream]
          threads=1
    [kafka.streams.my-other-stream]
      [kafka.streams.my-other-stream.num]
        [kafka.streams.my-other-stream.num.stream]
          threads=10</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  streams {
    'default' {
      num {
        stream {
          threads = 1
        }
      }
    }
    myOtherStream {
      num {
        stream {
          threads = 10
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    streams {
      default {
        num {
          stream {
            threads = 1
          }
        }
      }
      my-other-stream {
        num {
          stream {
            threads = 10
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "streams": {
      "default": {
        "num": {
          "stream": {
            "threads": 1
          }
        }
      },
      "my-other-stream": {
        "num": {
          "stream": {
            "threads": 10
          }
        }
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The above configuration sets the <code>num.stream.threads</code> setting of the Kafka <code>StreamsConfig</code> to <code>1</code> for the <code>default</code> stream, and the same setting to <code>10</code> for a stream named <code>my-stream</code>.</p>
</div>
<div class="paragraph">
<p>You can then inject an <code><a href="../api/io/micronaut/configuration/kafka/streams/ConfiguredStreamBuilder.html">ConfiguredStreamBuilder</a></code> specifically for the above configuration using <code>jakarta.inject.Named</code>:</p>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Singleton
@Named("my-other-stream")
KStream&lt;String, String&gt; myOtherKStream(ConfiguredStreamBuilder builder)  {
    return builder.stream("my-other-stream");
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Singleton
@Named('my-other-stream')
KStream&lt;String, String&gt; myOtherKStream(ConfiguredStreamBuilder builder)  {
    return builder.stream('my-other-stream')
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Singleton
@Named("my-other-stream")
fun myOtherKStream(builder: ConfiguredStreamBuilder): KStream&lt;String, String&gt; {
    return builder.stream("my-other-stream")
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you do not provide a <code>@Named</code> on the <code>ConfiguredStreamBuilder</code> you have multiple KStreams defined that share the default configurations like client id, application id, etc. It is advisable when using multiple streams in a single app to provide a <code>@Named</code> instance of <code>ConfiguredStreamBuilder</code> for each stream.
</td>
</tr>
</table>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Kafka Streams Word Count</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">@Singleton
@Named("my-stream")
KStream&lt;String, String&gt; myStream(ConfiguredStreamBuilder builder) {</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Kafka Streams Word Count</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">@Singleton
@Named('my-stream')
KStream&lt;String, String&gt; myStream(ConfiguredStreamBuilder builder) {</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="title">Kafka Streams Word Count</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">@Singleton
@Named("my-stream")
fun myStream(builder: ConfiguredStreamBuilder): KStream&lt;String, String&gt; {</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">Configuring Kafka Streams for testing</div>
<p>When writing a test without starting the actual Kafka server, you can instruct Micronaut not to start Kafka Streams. To do this create a config file suffixed with an environment name, such as <code>application-test.yml</code> and set the <code>kafka.streams.[STREAM-NAME].start-kafka-streams</code> to <code>false</code>.</p>
</div>
<div class="paragraph">
<p>For example in <code>application-test.yml</code>:</p>
</div>
<div class="openblock">
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.streams.default.start-kafka-streams=false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    streams:
        default:
            start-kafka-streams: false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.streams]
    [kafka.streams.default]
      start-kafka-streams=false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  streams {
    'default' {
      startKafkaStreams = false
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    streams {
      default {
        start-kafka-streams = false
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "streams": {
      "default": {
        "start-kafka-streams": false
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>

<h2 id="kafkaStreamInteractiveQuery"><a class="anchor" href="#kafkaStreamInteractiveQuery"></a>8.1 Interactive Query Service</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaStreams/kafkaStreamInteractiveQuery.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>When using streams you can set a state store for your stream using a store builder and telling the stream to store its data.  In the above example for the Kafka Streams Word Count, the output is materialized to a named store that can later be retrieved via the Interactive Query Service.  Apache Kafka docs <a href="https://kafka.apache.org/10/documentation/streams/developer-guide/interactive-queries.html#querying-local-key-value-stores">available here</a>.</p>
</div>
<div class="paragraph">
<p>You can inject the <a href="../api/io/micronaut/configuration/kafka/streams/InteractiveQueryService.html">InteractiveQueryService</a> and use the method <code>getQueryableStore(String storeName, QueryableStoreType&lt;T&gt; storeType)</code> to get values from a state store.</p>
</div>
<div class="paragraph">
<p>An example service that wraps the <code>InteractiveQueryService</code> is included below.  This is here to illustrate that when calling the <code>getQueryableStore</code> method you must provide the store name and preferably the type of key and value you are trying to retrieve.</p>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.streams.InteractiveQueryService;
import io.micronaut.context.annotation.Requires;
import jakarta.inject.Singleton;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;

import java.util.Optional;

/**
 * Example service that uses the InteractiveQueryService in a reusable way.  This is only intended as an example.
 */
@Singleton
public class InteractiveQueryServiceExample {

    private final InteractiveQueryService interactiveQueryService;

    public InteractiveQueryServiceExample(InteractiveQueryService interactiveQueryService) {
        this.interactiveQueryService = interactiveQueryService;
    }

    /**
     * Method to get the word state store and word count from the store using the interactive query service.
     *
     * @param stateStore the name of the state store ie "foo-store"
     * @param word       the key to get, in this case the word as the stream and ktable have been grouped by word
     * @return the Long count of the word in the store
     */
    public Long getWordCount(String stateStore, String word) {
        Optional&lt;ReadOnlyKeyValueStore&lt;String, Long&gt;&gt; queryableStore = interactiveQueryService.getQueryableStore(
            stateStore, QueryableStoreTypes.keyValueStore());
        return queryableStore.map(kvReadOnlyKeyValueStore -&gt;
            kvReadOnlyKeyValueStore.get(word)).orElse(0L);
    }

    /**
     * Method to get byte array from a state store using the interactive query service.
     *
     * @param stateStore the name of the state store ie "bar-store"
     * @param blobName   the key to get, in this case the name of the blob
     * @return the byte[] stored in the state store
     */
    public byte[] getBytes(String stateStore, String blobName) {
        Optional&lt;ReadOnlyKeyValueStore&lt;String, byte[]&gt;&gt; queryableStore = interactiveQueryService.getQueryableStore(
            stateStore, QueryableStoreTypes.keyValueStore());
        return queryableStore.map(stringReadOnlyKeyValueStore -&gt;
            stringReadOnlyKeyValueStore.get(blobName)).orElse(null);
    }

    /**
     * Method to get value V by key K.
     *
     * @param stateStore the name of the state store ie "baz-store"
     * @param name       the key to get
     * @return the value of type V stored in the state store
     */
    public &lt;K, V&gt; V getGenericKeyValue(String stateStore, K name) {
        Optional&lt;ReadOnlyKeyValueStore&lt;K, V&gt;&gt; queryableStore = interactiveQueryService.getQueryableStore(
            stateStore, QueryableStoreTypes.&lt;K, V&gt;keyValueStore());
        return queryableStore.map(kvReadOnlyKeyValueStore -&gt;
            kvReadOnlyKeyValueStore.get(name)).orElse(null);
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">import io.micronaut.configuration.kafka.streams.InteractiveQueryService
import io.micronaut.context.annotation.Requires;
import jakarta.inject.Singleton;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;

/**
 * Example service that uses the InteractiveQueryService in a reusable way.  This is only intended as an example.
 */
@Singleton
class InteractiveQueryServiceExample {

    private final InteractiveQueryService interactiveQueryService;

    InteractiveQueryServiceExample(InteractiveQueryService interactiveQueryService) {
        this.interactiveQueryService = interactiveQueryService;
    }

    /**
     * Method to get the word state store and word count from the store using the interactive query service.
     *
     * @param stateStore the name of the state store ie "foo-store"
     * @param word       the key to get, in this case the word as the stream and ktable have been grouped by word
     * @return the Long count of the word in the store
     */
    Long getWordCount(String stateStore, String word) {
        Optional&lt;ReadOnlyKeyValueStore&lt;String, Long&gt;&gt; queryableStore = interactiveQueryService.getQueryableStore(
                stateStore, QueryableStoreTypes.keyValueStore());
        return queryableStore.map(kvReadOnlyKeyValueStore -&gt;
                kvReadOnlyKeyValueStore.get(word)).orElse(0L);
    }

    /**
     * Method to get byte array from a state store using the interactive query service.
     *
     * @param stateStore the name of the state store ie "bar-store"
     * @param blobName   the key to get, in this case the name of the blob
     * @return the byte[] stored in the state store
     */
    byte[] getBytes(String stateStore, String blobName) {
        Optional&lt;ReadOnlyKeyValueStore&lt;String, byte[]&gt;&gt; queryableStore = interactiveQueryService.getQueryableStore(
                stateStore, QueryableStoreTypes.keyValueStore());
        return queryableStore.map(stringReadOnlyKeyValueStore -&gt;
                stringReadOnlyKeyValueStore.get(blobName)).orElse(null);
    }

    /**
     * Method to get value V by key K.
     *
     * @param stateStore the name of the state store ie "baz-store"
     * @param name       the key to get
     * @return the value of type V stored in the state store
     */
    &lt;K, V&gt; V getGenericKeyValue(String stateStore, K name) {
        Optional&lt;ReadOnlyKeyValueStore&lt;K, V&gt;&gt; queryableStore = interactiveQueryService.getQueryableStore(
                stateStore, QueryableStoreTypes.&lt;K, V&gt;keyValueStore());
        return queryableStore.map(kvReadOnlyKeyValueStore -&gt;
                kvReadOnlyKeyValueStore.get(name)).orElse(null);
    }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-kotlin hljs" data-lang="kotlin">import io.micronaut.configuration.kafka.streams.InteractiveQueryService
import io.micronaut.context.annotation.Requires
import jakarta.inject.Singleton
import org.apache.kafka.streams.state.QueryableStoreTypes
import org.apache.kafka.streams.state.ReadOnlyKeyValueStore

/**
 * Example service that uses the InteractiveQueryService in a reusable way.  This is only intended as an example.
 */
@Singleton
class InteractiveQueryServiceExample(private val interactiveQueryService: InteractiveQueryService) {
    /**
     * Method to get the word state store and word count from the store using the interactive query service.
     *
     * @param stateStore the name of the state store ie "foo-store"
     * @param word       the key to get, in this case the word as the stream and ktable have been grouped by word
     * @return the Long count of the word in the store
     */
    fun getWordCount(stateStore: String, word: String): Long {
        val queryableStore = interactiveQueryService.getQueryableStore(
            stateStore, QueryableStoreTypes.keyValueStore&lt;String, Long&gt;())
        return queryableStore.map { kvReadOnlyKeyValueStore: ReadOnlyKeyValueStore&lt;String, Long&gt; -&gt;
            kvReadOnlyKeyValueStore[word] }.orElse(0L)
    }

    /**
     * Method to get byte array from a state store using the interactive query service.
     *
     * @param stateStore the name of the state store ie "bar-store"
     * @param blobName   the key to get, in this case the name of the blob
     * @return the byte[] stored in the state store
     */
    fun getBytes(stateStore: String, blobName: String): ByteArray? {
        val queryableStore = interactiveQueryService.getQueryableStore(
            stateStore, QueryableStoreTypes.keyValueStore&lt;String, ByteArray&gt;())
        return queryableStore.map { stringReadOnlyKeyValueStore: ReadOnlyKeyValueStore&lt;String, ByteArray&gt; -&gt;
            stringReadOnlyKeyValueStore[blobName] }.orElse(null)
    }

    /**
     * Method to get value V by key K.
     *
     * @param stateStore the name of the state store ie "baz-store"
     * @param name       the key to get
     * @return the value of type V stored in the state store
     */
    fun &lt;K, V&gt; getGenericKeyValue(stateStore: String, name: K): V {
        val queryableStore = interactiveQueryService.getQueryableStore(
            stateStore, QueryableStoreTypes.keyValueStore&lt;K, V&gt;())
        return queryableStore.map { kvReadOnlyKeyValueStore: ReadOnlyKeyValueStore&lt;K, V&gt; -&gt;
            kvReadOnlyKeyValueStore[name] }.orElse(null)
    }
}</code></pre>
</div>
</div>

<h2 id="kafkaStreamHealth"><a class="anchor" href="#kafkaStreamHealth"></a>8.2 Kafka Stream Health Checks</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaStreams/kafkaStreamHealth.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>In addition to <code>http-server-netty</code>, if the <code>management</code> dependency is added, then Micronaut&#8217;s <a href="https://docs.micronaut.io/latest/guide/#healthEndpoint">Health Endpoint</a> can be used to expose the health status of the Kafka streams application.</p>
</div>
<div class="paragraph">
<p>For example stream health at the <code>/health</code> endpoint will return:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
  "status": "UP",
  "details": {
    "kafkaStreams": {
      "name": "my-application",
      "status": "UP",
      "details": {
        "named-stream": {
          "name": "my-application",
          "status": "UP",
          "details": {
            "adminClientId": "my-consumer-id-admin",
            "restoreConsumerClientId": "my-consumer-id-StreamThread-1-restore-consumer",
            "threadState": "RUNNING",
            "producerClientIds": [
              "my-consumer-id-StreamThread-1-producer"
            ],
            "consumerClientId": "my-consumer-id-StreamThread-1-consumer",
            "threadName": "my-consumer-id-StreamThread-1"
          }
        }
      }
    },
    ...
  }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
By default, the details visible above are only shown to authenticated users. See the <a href="https://docs.micronaut.io/latest/guide/#healthEndpoint">Health Endpoint</a> documentation for how to configure that setting.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you wish to disable the Kafka streams health check while still using the <code>management</code> dependency you can set the property <code>kafka.health.streams.enabled</code> to <code>false</code> in your application configuration.</p>
</div>
<div class="openblock">
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.health.streams.enabled=false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    health:
        streams:
            enabled: false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.health]
    [kafka.health.streams]
      enabled=false</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  health {
    streams {
      enabled = false
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    health {
      streams {
        enabled = false
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "health": {
      "streams": {
        "enabled": false
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>

<h2 id="kafkaStreamExceptions"><a class="anchor" href="#kafkaStreamExceptions"></a>8.3 Handling Uncaught Exceptions</h2>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaStreams/kafkaStreamExceptions.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>Since version 2.8.0, Kafka allows you to <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/errors/StreamsUncaughtExceptionHandler.html">handle uncaught exceptions</a> that may be thrown from your streams. This handler must return the action that must be taken, depending on the thrown exception.</p>
</div>
<div class="paragraph">
<p>There are three possible <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/streams/errors/StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.html">responses</a>: <code>REPLACE_THREAD</code>, <code>SHUTDOWN_CLIENT</code>, or <code>SHUTDOWN_APPLICATION</code>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can find more details about this mechanism <a href="https://developer.confluent.io/tutorials/error-handling/confluent.html">here</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you just want to take the same action every time, you can set the application property <code>kafka.streams.[STREAM-NAME].uncaught-exception-handler</code> to a valid action, such as <code>REPLACE_THREAD</code>.</p>
</div>
<div class="paragraph">
<p>For example in <code>application-test.yml</code>:</p>
</div>
<div class="openblock">
<div class="content">
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties">kafka.streams.my-stream.uncaught-exception-handler=REPLACE_THREAD</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">kafka:
    streams:
        my-stream:
            uncaught-exception-handler: REPLACE_THREAD</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-toml hljs" data-lang="toml">[kafka]
  [kafka.streams]
    [kafka.streams.my-stream]
      uncaught-exception-handler="REPLACE_THREAD"</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy-config hljs" data-lang="groovy-config">kafka {
  streams {
    myStream {
      uncaughtExceptionHandler = "REPLACE_THREAD"
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-hocon hljs" data-lang="hocon">{
  kafka {
    streams {
      my-stream {
        uncaught-exception-handler = "REPLACE_THREAD"
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="listingblock multi-language-sample">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json-config hljs" data-lang="json-config">{
  "kafka": {
    "streams": {
      "my-stream": {
        "uncaught-exception-handler": "REPLACE_THREAD"
      }
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>To implement your own handler, you can listen to the application event <a href="../api/io/micronaut/configuration/kafka/streams/event/BeforeKafkaStreamStart.html">BeforeKafkaStreamStart</a> and configure the streams with your own business logic:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">import io.micronaut.configuration.kafka.streams.event.BeforeKafkaStreamStart;
import io.micronaut.context.annotation.Requires;
import io.micronaut.context.event.ApplicationEventListener;
import jakarta.inject.Singleton;
import org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler;

@Singleton
public class MyStreamsUncaughtExceptionHandler
    implements ApplicationEventListener&lt;BeforeKafkaStreamStart&gt;, StreamsUncaughtExceptionHandler {

    boolean dangerAvoided = false;

    @Override
    public void onApplicationEvent(BeforeKafkaStreamStart event) {
        event.getKafkaStreams().setUncaughtExceptionHandler(this);
    }

    @Override
    public StreamThreadExceptionResponse handle(Throwable exception) {
        if (exception.getCause() instanceof MyException) {
            this.dangerAvoided = true;
            return StreamThreadExceptionResponse.REPLACE_THREAD;
        }
        return StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;
    }
}</code></pre>
</div>
</div>

<h1 id="kafkaGuides"><a class="anchor" href="#kafkaGuides"></a>9 Guides</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/kafkaGuides.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>See the following list of guides to learn more about working with Kafka in the Micronaut Framework:</p>
</div>
<div class="paragraph">
<p><a href="https://guides.micronaut.io/latest/tag-kafka.html" class="bare">https://guides.micronaut.io/latest/tag-kafka.html</a></p>
</div>

<h1 id="repository"><a class="anchor" href="#repository"></a>10 Repository</h1>

<div class='contribute-btn'>
    <button type='button' class='btn btn-default' onclick='window.location.href="https://github.com/micronaut-projects/micronaut-kafka/edit/5.6.x/src/main/docs/guide/repository.adoc"'>
        <i class='fa fa-pencil-square-o'></i> Improve this doc
    </button>
</div>


<div class="paragraph">
<p>You can find the source code of this project in this repository:</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/micronaut-projects/micronaut-kafka">https://github.com/micronaut-projects/micronaut-kafka</a></p>
</div>

    </div>
</div>

<script type="text/javascript">

</script>
</body>
</html>
